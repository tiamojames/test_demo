<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</title>
  <meta name="generator" content="Jekyll v3.9.0">
  <meta property="og:title" content="TODO: title">
  <meta property="og:locale" content="en_US">
  <meta name="twitter:card" content="summary">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="style.css">
</head>

<body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed="">
  <section class="page-header">
    </section>

  <section class="main-content">
    <h4 id="broadcast" style="margin: 1em 0; overflow: hidden; white-space: nowrap;">
      <div class="marquee-container">
        <div class="marquee-content">
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> WenetSpeech-Yue</a>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> WenetSpeech-Yue</a>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> WenetSpeech-Yue</a>
        </div>
      </div>
    </h4>
    
    <style>
    .marquee-container {
      display: flex;
      width: 100%;
      overflow: hidden;
    }
    /* æ»šåŠ¨é€Ÿåº¦è°ƒæ…¢ï¼ˆ80ç§’/è½®ï¼Œæ•°å€¼è¶Šå¤§è¶Šæ…¢ï¼‰ï¼Œä¿ç•™æ— é™å¾ªç¯ */
    .marquee-content {
      display: flex;
      animation: marquee 80s linear infinite;
      will-change: transform; /* æå‡åŠ¨ç”»æµç•…åº¦ */
    }
    @keyframes marquee {
      0% { transform: translateX(100%); } /* ä»å³ä¾§å®Œå…¨è¿›å…¥ */
      100% { transform: translateX(-100%); } /* ä»å·¦ä¾§å®Œå…¨é€€å‡ºï¼Œæ— ç¼è¡”æ¥ */
    }
    /* å¯é€‰ï¼šç»™é“¾æ¥åŠ  hover æ ·å¼ï¼Œæç¤ºå¯äº¤äº’ */
    .marquee-content a {
      color: #2563eb; /* é“¾æ¥è“è‰²ï¼Œé€‚é…å¤šæ•°é¡µé¢é£æ ¼ */
      text-decoration: underline;
      margin: 0 2px; /* é¿å…é“¾æ¥ä¸å‰åæ–‡æœ¬è´´å¤ªè¿‘ */
    }
    </style>
    
    <script>
    // ç²¾å‡†æ§åˆ¶åŠ¨ç”»æš‚åœ/æ’­æ”¾ï¼ˆåªé’ˆå¯¹æ»šåŠ¨å†…å®¹ï¼Œä¸å½±å“å…¶ä»–å…ƒç´ ï¼‰
    function stopMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'paused';
    }
    function startMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'running';
    }
    </script>
    
    <h1 id="">
      <center>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</center>
    </h1>
  
    <div style="text-align:center; line-height:1.6; font-family:Arial, sans-serif;">
      <p align="center">
        Hanke Xie<sup>1,2</sup><sup>,*</sup>, Haopeng Lin<sup>2</sup><sup>,*</sup>, Wenxiao Cao<sup>2</sup>, Dake Guo<sup>1</sup>, Wenjie Tian<sup>1</sup>, 
        Jun Wu<sup>2</sup>, Hanlin Wen<sup>2</sup>, Ruixuan Shang<sup>2</sup>, Hongmei Liu<sup>2</sup>, Zhiqi Jiang<sup>2</sup>, 
        Yuepeng Jiang<sup>1</sup>, Wenxi Chen<sup>2</sup>, Ruiqi Yan<sup>2</sup>, Jiale Qian<sup>2</sup>, Yichao Yan<sup>2</sup>, 
        Shunshun Yin<sup>2</sup>, Ming Tao<sup>2</sup>, Lei Xie<sup>1</sup><sup>,â•€</sup>, Xinsheng Wang<sup>2</sup><sup>,â€ </sup>
      </p>      
    <p align="center">
      <sup>1</sup> Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University, Xiâ€™an, China <br>
      <sup>2</sup> Soul AI Lab, China <br>
    </p>
      
  </div>


    <p align="center">
    ğŸ“‘ <a href="https://arxiv.org/abs/2509.18004">Paper</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ™ <a href="https://github.com/Soul-AILab/SoulX-Podcast">GitHub</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ¤— <a href="https://huggingface.co/collections/Soul-AILab/soulx-podcast">HuggingFace</a>
    <br>
    ğŸ¤ <a href="https://github.com/Soul-AILab/SoulX-Podcast/blob/demopage/index.html">Demo Page</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ’¬ <a href="https://github.com/Soul-AILab/SoulX-Podcast?tab=readme-ov-file#contact">Contact Us</a>
    </p>

    <div style="text-align:center; margin-top:10px; position: sticky; top: 10px; z-index: 1000;">
      <nav style="
        background: rgba(0, 0, 0, 0.5);
        padding: 12px 24px;
        display: inline-block;      /* å®½åº¦éšå†…å®¹ */
        border-radius: 10px;
        backdrop-filter: blur(6px); /* æ¯›ç»ç’ƒï¼Œæ”¯æŒçš„æµè§ˆå™¨ä¼šæ›´å¥½çœ‹ */
      ">
        <a href="#abstract" class="nav-link">Abstract</a>
        <a href="#video" class="nav-link">Demo Video</a>
        <a href="#model" class="nav-link">Model Overview</a>
        <a href="#podcast-demo" class="nav-link">Podcast Generation</a> 
        <a href="#dialect-demo" class="nav-link">Dialectal Controls</a>
        <a href="#paralinguistic-demo" class="nav-link">Paralinguistic Controls</a>
        <a href="#longform-demo" class="nav-link">Long-form Podcast</a>
      </nav>
    </div>
    
    <style>
      /* é“¾æ¥æ ·å¼ï¼šä¿æŒåŸå­—å·ï¼Œhover å˜è“+ä¸‹åˆ’çº¿ */
      .nav-link {
        color: white;
        margin: 0 15px;
        text-decoration: none;
        font-size: 16px;             /* ä½ åŸæ¥çš„å¤§å° */
        transition: color 0.2s, text-decoration 0.2s;
      }
      .nav-link:hover {
        color: #66ccff;              /* æµ…è“è‰² hover */
        text-decoration: underline;
      }
    </style>


    <h2 id="abstract" style="text-align: center;">Abstract<a name="abstract"></a></h2>
    <p style="text-align: justify;">Recent advances in text-to-speech (TTS) synthesis have significantly improved
      speech expressiveness and naturalness. However, most existing systems are tailored
      for single-speaker synthesis and fall short in generating coherent multi-speaker
      conversational speech. This technical report presents SoulX-Podcast, a system
      designed for multi-turn, multi-speaker conversational speech generation while si-
      multaneously achieving state-of-the-art performance in conventional TTS tasks. To
      meet the higher naturalness demands of multi-turn spoken dialogue, SoulX-Podcast
      integrates a range of paralinguistic controls and supports both Mandarin and En-
      glish, as well as several Chinese dialects, including Sichuanese, Henanese, and
      Cantonese, enabling more personalized podcast-style speech generation. Experi-
      mental results demonstrate that SoulX-Podcast can continuously produce over 90
      minutes of conversation with stable speaker timbre and smooth speaker transitions.
      Moreover, speakers exhibit contextually adaptive prosody, reflecting natural rhythm
      and intonation changes as dialogues progress. Across multiple evaluation metrics,
      SoulX-Podcast achieves state-of-the-art performance in both single-speaker TTS
      and multi-turn conversational speech synthesis.</p>


    <h2 id="video" style="text-align:center;">Demo Video</h2>
    
    <div style="display:flex; justify-content:center; gap:40px; margin-top:20px; flex-wrap:wrap;">
      <div style="text-align:center; max-width:900px; width:100%;">
        <div style="position:relative; width:100%; max-width:900px; aspect-ratio:16/9; background:#000;">
        <iframe 
          width="100%" 
          height="100%" 
          src="raw/video/demo_video.mp4" 
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
          allowfullscreen
          style="position:absolute; inset:0;"
        ></iframe>
        </div>
      </div>
    </div>

    <h2 id="model overview" style="text-align: center;">Model Overview<a name="model overview"></a></h2>
    <div style="text-align:center;">
      <img src="src/figs/soulxpodcast_infer.pdf" alt="Model overviewof SoulX-Podcast. The model supports cross-dialect prompting, where
      a Mandarin prompt can generate speech in target dialects with Dialect-Guided Prompting (DGP) method." style="width:80%; height:auto;">
    </div>

    <h2 id="pipeline" style="text-align: center;">SoulX-Data-Pipeline<a name="pipeline"></a></h2>
    <p style="text-align: justify;">In contrast to monologue speech, the processing of dialogue speech necessitates not only obtaining
      aligned transcripts but also distinguishing between speakers explicitly. As shown in Figure 2, the
      overall workflow comprises speech enhancement, audio segmentation and speaker diarization, text
      transcription, and quality filtering. Additionally, to facilitate paralinguistic and dialectal controllability,
      further information is extracted and annotated</p>

    <div style="text-align:center;">
      <img src="src/figs/soulx_datapipeline_v3.png" alt="Processing pipeline for in-the-wild dialogue speech data" style="width:80%; height:auto;">
    </div>

    <hr>
    <h2 id="podcast-demo" style="text-align: center;">Podcast Generation: Multi-Speaker Conversation<a name="podcast-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">å±•ç¤ºæˆ‘ä»¬æ¨¡å‹åœ¨å¤šè½®ã€å¤šäººç‰©æ’­å®¢å¯¹è¯ç”Ÿæˆä¸­çš„è‡ªç„¶åº¦å’Œè¿è´¯æ€§ã€‚</p>

    <table style="margin: 0 auto; width: 95%; border-collapse: collapse; text-align: center; font-size: 1em;">
      <thead>
        <tr>
          <th style="border: 1px solid #ccc; padding: 12px; width: 40%;">Dialogue Script (Speaker Turns)</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 30%;">Reference Podcast Audio</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 30%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">
            **Speaker A:** æœ€è¿‘åœ¨å¿™å•¥å‘¢ï¼Ÿå¬è¯´ä½ ä»¬éƒ¨é—¨æ–°ç«‹äº†ä¸ªå¤§é¡¹ç›®ï¼Ÿ<br>
            **Speaker B:** å—¨ï¼Œåˆ«æäº†ï¼Œé‚£ä¸ªé¡¹ç›®éš¾åº¦è¶…é«˜ï¼Œæˆ‘ä»¬æ¯å¤©éƒ½å¾—åŠ ç­åˆ°æ·±å¤œã€‚<br>
            **Speaker A:** è¿™ä¹ˆæ‹¼ï¼ä¸è¿‡è¯è¯´å›æ¥ï¼Œè¿™æˆæœè¦æ˜¯å‡ºæ¥äº†ï¼Œè‚¯å®šç‰¹æœ‰æˆå°±æ„Ÿã€‚<br>
            **Speaker B:** æ˜¯å•Šï¼Œç°åœ¨å°±æ˜¯å’¬ç‰™åšæŒï¼Œå¸Œæœ›æ—©ç‚¹çœ‹åˆ°æ›™å…‰ã€‚
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Podcast_samples/ref/podcast_dialogue_01_ref.wav" type="audio/wav">
            </audio>
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Podcast_samples/sys/podcast_dialogue_01_gen.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="dialect-demo" style="text-align: center;">Dialectal Controls: Cross-Dialect Synthesis<a name="dialect-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">å±•ç¤ºæ¨¡å‹åœ¨ä¸åŒä¸­æ–‡æ–¹è¨€ï¼ˆå¦‚ç²¤è¯­ã€å››å·è¯ã€æ²³å—è¯ï¼‰ä¸Šçš„ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒ…æ‹¬æ–¹è¨€çš„åˆ‡æ¢å’Œå£°è‰²ä¿æŒã€‚</p>

    <table style="margin: 0 auto; width: 95%; border-collapse: collapse; text-align: center; font-size: 1em;">
      <thead>
        <tr>
          <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">Text Input (Mandarin Pinyin)</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">Target Dialect</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">Reference Audio (Source Speaker)</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">
            ä½ ä»Šæ™šå¾—å””å¾—é—²å•Šï¼Ÿä¸å¦‚æˆ‘å“‹å‡ºå»é£Ÿé¥­å•¦ã€‚<br>
            *Original Mandarin Text: ä½ ä»Šæ™šæœ‰æ²¡æœ‰ç©ºå•Šï¼Ÿä¸å¦‚æˆ‘ä»¬å‡ºå»åƒé¥­å§ã€‚
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">**Cantonese** (ç²¤è¯­)</td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Dialect_samples/ref/cantonese_ref.wav" type="audio/wav">
            </audio>
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Dialect_samples/sys/cantonese_gen.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">
            æˆ‘è·Ÿä½ è¯´å“¦ï¼Œè¿™å‡ å¤©é‡åº†çš„å¤©æ°”çœŸçš„æ˜¯åˆçƒ­åˆæ¹¿ï¼Œç®€ç›´æ²¡æ³•å¿å—ã€‚<br>
            *Dialect example from your original code, adapted for new table.
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">**Sichuanese** (å››å·è¯)</td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Dialect_samples/ref/sichuanese_ref.wav" type="audio/wav">
            </audio>
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Dialect_samples/sys/sichuanese_gen.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="paralinguistic-demo" style="text-align: center;">Paralinguistic Controls: Emotion & Style<a name="paralinguistic-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">å±•ç¤ºæ¨¡å‹å¯¹è¯­éŸ³ä¸­éè¯­è¨€ä¿¡æ¯ï¼ˆå¦‚æƒ…æ„Ÿã€è¯­é€Ÿã€åœé¡¿ç­‰ï¼‰çš„ç²¾ç»†æ§åˆ¶èƒ½åŠ›ã€‚</p>

    <table style="margin: 0 auto; width: 95%; border-collapse: collapse; text-align: center; font-size: 1em;">
      <thead>
        <tr>
          <th style="border: 1px solid #ccc; padding: 12px; width: 30%;">Text Input</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 20%;">Target Emotion/Style</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">Reference Audio (Target Emotion)</th>
          <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">
            ä½ è¯´è¯èƒ½ä¸èƒ½ä¸è¦é‚£ä¹ˆå†²ï¼Œæˆ‘è·Ÿä½ è®²ä¸æ˜¯æ¯ä¸ªäººéƒ½æƒ¯ç€ä½ è€æ€§å­çš„ï¼Œæˆ‘è„¾æ°”ä¹Ÿæœ‰ç‚¹å„¿çˆ†ï¼
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">**Anger** (æ„¤æ€’)</td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Paralinguistic_samples/ref/anger_ref.wav" type="audio/wav">
            </audio>
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Paralinguistic_samples/sys/anger_gen.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">
            å“‡å¡ï¼è¿™ä¸ªå‘¨æœ«çš„æ—…è¡Œè®¡åˆ’ç®€ç›´å¤ªæ£’äº†ï¼æˆ‘ä»¬ä¸€å®šè¦ç©ä¸ªç—›å¿«ï¼
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">**Joy** (å¼€å¿ƒ)</td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Paralinguistic_samples/ref/joy_ref.wav" type="audio/wav">
            </audio>
          </td>
          <td style="border: 1px solid #ccc; padding: 12px;">
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/Paralinguistic_samples/sys/joy_gen.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="longform-demo" style="text-align: center;">Long-form Podcast: Coherence and Stability<a name="longform-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">å±•ç¤º SoulX-Podcast åœ¨ç”Ÿæˆè¶…è¿‡ 5 åˆ†é’Ÿç”šè‡³æ›´é•¿æ—¶é—´çš„é•¿ç¯‡å¯¹è¯ä¸­ï¼Œä¿æŒäººç‰©å£°è‰²ç¨³å®šã€æƒ…æ„Ÿè¿è´¯çš„èƒ½åŠ›ã€‚</p>

    <div style="margin: 20px auto; width: 80%; max-width: 900px; text-align: left; padding: 15px; border: 1px solid #ddd; border-radius: 8px;">
      <h3 style="text-align: center; margin-top: 0;">é•¿ç¯‡å¯¹è¯ç‰‡æ®µ (~8 Minutes)</h3>
      <p style="font-size: 14px; margin-bottom: 10px; color: #777;">
        **ä¸»é¢˜:** å¯¹æœ€è¿‘ä¸€æœŸç§‘æŠ€æ–°é—»çš„è®¨è®ºã€‚
      </p>
      <div style="margin-bottom: 20px;">
        <p style="font-weight: bold; margin-bottom: 5px;">SoulX-Podcast Generated Audio (Multi-Speaker):</p>
        <audio controls style="width: 100%;">
          <source src="raw/Longform_samples/longform_podcast_full_gen.mp3" type="audio/mp3">
        </audio>
      </div>
      <div style="margin-bottom: 0;">
        <p style="font-weight: bold; margin-bottom: 5px;">Reference Audio (Actual Podcast):</p>
        <audio controls style="width: 100%;">
          <source src="raw/Longform_samples/longform_podcast_full_ref.mp3" type="audio/mp3">
        </audio>
      </div>
      <p style="font-size: 12px; text-align: right; margin-top: 10px; color: #999;">
        *å»ºè®®ä½¿ç”¨è€³æœºæ”¶å¬ï¼Œä»¥è¯„ä¼°å£°è‰²ä¸€è‡´æ€§å’Œå¯¹è¯æµç•…åº¦ã€‚*
      </p>
    </div>

    </section>
</body>

</html>