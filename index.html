<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</title>
  <meta name="generator" content="Jekyll v3.9.0">
  <meta property="og:title" content="TODO: title">
  <meta property="og:locale" content="en_US">
  <meta name="twitter:card" content="summary">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="style.css">
</head>

<body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed="">
  <section class="page-header">
    </section>

  <section class="main-content">
    <h4 id="broadcast" style="margin: 1em 0; overflow: hidden; white-space: nowrap;">
      <div class="marquee-container">
        <div class="marquee-content">
          📢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> SoulX-Podcast</a>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          📢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> SoulX-Podcast</a>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          📢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> SoulX-Podcast</a>
        </div>
      </div>
    </h4>
    
    <style>
    .marquee-container {
      display: flex;
      width: 100%;
      overflow: hidden;
    }
    .marquee-content {
      display: flex;
      animation: marquee 80s linear infinite;
      will-change: transform;
    }
    @keyframes marquee {
      0% { transform: translateX(100%); }
      100% { transform: translateX(-100%); }
    }
    .marquee-content a {
      color: #2563eb;
      text-decoration: underline;
      margin: 0 2px;
    }
    </style>
    
    <script>
    function stopMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'paused';
    }
    function startMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'running';
    }
    </script>
    
    <h1 id="">
      <center>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</center>
    </h1>
  
    <div style="text-align:center; line-height:1.6; font-family:Arial, sans-serif;">
      <p align="center">
        Hanke Xie<sup>1,2</sup><sup>,*</sup>, Haopeng Lin<sup>2</sup><sup>,*</sup>, Wenxiao Cao<sup>2</sup>, Dake Guo<sup>1</sup>, Wenjie Tian<sup>1</sup>, 
        Jun Wu<sup>2</sup>, Hanlin Wen<sup>2</sup>, Ruixuan Shang<sup>2</sup>, Hongmei Liu<sup>2</sup>, Zhiqi Jiang<sup>2</sup>, 
        Yuepeng Jiang<sup>1</sup>, Wenxi Chen<sup>2,3</sup>, Ruiqi Yan<sup>2,3</sup>, Jiale Qian<sup>2</sup>, Yichao Yan<sup>2</sup>, 
        Shunshun Yin<sup>2</sup>, Ming Tao<sup>2</sup>, Xie Chen<sup>3</sup>, Lei Xie<sup>1</sup><sup>,‡</sup>, Xinsheng Wang<sup>2</sup><sup>,‡</sup>
      </p>      
      <p align="center">
        <sup>1</sup> Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University, Xi’an, China <br>
        <sup>2</sup> Soul AI Lab, China <br>
        <sup>3</sup> X-LANCE Lab, Shanghai Jiao Tong University, China <br>
      </p>
    </div>

    <p align="center">
    📑 <a href="https://arxiv.org/abs/2509.18004">Paper</a> &nbsp&nbsp | &nbsp&nbsp 
    🐙 <a href="https://github.com/Soul-AILab/SoulX-Podcast">GitHub</a> &nbsp&nbsp | &nbsp&nbsp 
    🤗 <a href="https://huggingface.co/collections/Soul-AILab/soulx-podcast">HuggingFace</a>
    <br>
    🎤 <a href="https://github.com/Soul-AILab/SoulX-Podcast/blob/demopage/index.html">Demo Page</a> &nbsp&nbsp | &nbsp&nbsp 
    💬 <a href="https://github.com/Soul-AILab/SoulX-Podcast?tab=readme-ov-file#contact">Contact Us</a>
    </p>

    <div style="text-align:center; margin-top:10px; position: sticky; top: 10px; z-index: 1000;">
      <nav style="
        background: rgba(0, 0, 0, 0.5);
        padding: 12px 24px;
        display: inline-block;
        border-radius: 10px;
        backdrop-filter: blur(6px);
      ">
        <a href="#abstract" class="nav-link">Abstract</a>
        <a href="#video" class="nav-link">Demo Video</a>
        <a href="#model" class="nav-link">Model Overview</a>
        <a href="#podcast-demo" class="nav-link">Podcast Generation</a> 
        <a href="#dialect-demo" class="nav-link">Dialectal Controls</a>
        <a href="#paralinguistic-demo" class="nav-link">Paralinguistic Controls</a>
        <a href="#longform-demo" class="nav-link">Long-form Podcast</a>
      </nav>
    </div>
    
    <style>
      .nav-link {
        color: white;
        margin: 0 15px;
        text-decoration: none;
        font-size: 16px;
        transition: color 0.2s, text-decoration 0.2s;
      }
      .nav-link:hover {
        color: #66ccff;
        text-decoration: underline;
      }
    </style>

    <style>
      /* 表格通用美化 */
      .demo-table {
        margin: 2em auto;
        width: 95%;
        border-collapse: collapse;
        text-align: center; /* 默认水平居中 */
        font-size: 1em; 
      }
      .demo-table th, .demo-table td {
        border: 1px solid #ccc;
        padding: 12px 15px;
        vertical-align: middle; /* 核心修改：默认所有单元格垂直居中 */
      }
      /* 表头样式 */
      .demo-table th {
        background-color: #f4f4f4;
        font-weight: 600;
      }
      
      /* 脚本列样式 */
      .demo-table td:first-child {
        text-align: left;    /* 覆盖水平居中 */
        font-size: 0.9em;    /* 减小字体 */
        line-height: 1.5;    /* 减小行距 */
        vertical-align: top; /* 核心修改：覆盖垂直居中，保持顶部对齐 */
      }
      
      /* 参考音频容器样式 */
      .ref-audio-container {
        text-align: left; /* 覆盖水平居中 */
        padding-left: 20px !important; 
      }
      .ref-audio-container b {
        font-size: 0.95em;
        color: #333;
      }
      .ref-audio-container audio {
        width: 100%; 
        max-width: 250px;
        margin-top: 4px;
        margin-bottom: 8px; 
      }
      
      /* ===== (新) VibeVoice 滚动字幕样式 ===== */
      .transcript {
        max-height: 30vh; /* 设定一个最大高度 */
        overflow-y: auto; /* 允许垂直滚动 */
        padding: 8px;
        border: 1px solid #ddd; /* 统一边框 */
        border-radius: 8px; /* 统一圆角 */
        background: #fff;
        scroll-behavior: smooth;
        margin-top: 15px; /* 与上方播放器留出间距 */
      }
      .line {
        display: grid;
        grid-template-columns: 84px 75px 1fr; /* 时间 | 说话人 | 文本 */
        gap: 10px;
        padding: 8px 10px;
        border-radius: 6px;
        border: 1px solid transparent;
        cursor: pointer;
        font-size: 0.9em;
        line-height: 1.5;
      }
      .line:hover {
        background: #f7f7f7;
      }
      .line.active {
        background: rgba(0, 102, 204, 0.08); /* 高亮背景色 */
        border-color: #0066cc; /* 高亮边框色 */
      }
      .ts, .spk {
        font-family: ui-monospace, Menlo, Consolas, monospace;
        color: #333;
        font-size: 14px;
        align-self: center; /* 垂直居中 */
        opacity: .9;
        white-space: nowrap;
      }
      .ts { text-align: right; }
      .spk { text-align: left; font-weight: 600; }
      .txt {
        white-space: pre-wrap;
        word-break: break-word;
        overflow-wrap: anywhere;
        text-align: left; /* 文本左对齐 */
      }
      /* ================================== */
    </style>
    <h2 id="abstract" style="text-align: center;">Abstract<a name="abstract"></a></h2>
    <p style="text-align: justify;">Recent advances in text-to-speech (TTS) synthesis have significantly improved speech expressiveness and naturalness. However, most existing systems are tailored for single-speaker synthesis and fall short in generating coherent multi-speaker conversational speech. This technical report presents SoulX-Podcast, a system designed for podcast-style multi-turn, multi-speaker dialogic speech generation, while also achieving state-of-the-art performance in conventional text-to-speech (TTS) tasks.
      To meet the higher naturalness demands of multi-turn spoken dialogue, SoulX-Podcast integrates a range of paralinguistic controls and supports both Mandarin and English, as well as several Chinese dialects, including Sichuanese, Henanese, and Cantonese, enabling more personalized podcast-style speech generation. Experimental results demonstrate that SoulX-Podcast can continuously produce over 90 minutes of conversation with stable speaker timbre and smooth speaker transitions. Moreover, speakers exhibit contextually adaptive prosody, reflecting natural rhythm and intonation changes as dialogues progress. Across multiple evaluation metrics, SoulX-Podcast achieves state-of-the-art performance in both monologue TTS and multi-turn conversational speech synthesis.
    </p>


    <h2 id="video" style="text-align:center;">Demo Video</h2>
    
    <div style="display:flex; justify-content:center; gap:40px; margin-top:20px; flex-wrap:wrap;">
      <div style="text-align:center; max-width:900px; width:100%;">
        <div style="position:relative; width:100%; max-width:900px; aspect-ratio:16/9; background:#000;">
        <iframe 
          width="100%" 
          height="100%" 
          src="raw/video/demo_video.mp4" 
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
          allowfullscreen
          style="position:absolute; inset:0;"
        ></iframe>
        </div>
      </div>
    </div>

    <h2 id="model overview" style="text-align: center;">Model Overview<a name="model overview"></a></h2>
    <div style="text-align:center;">
      <img src="src/figs/soulxpodcast_v3.png" alt="Model overview of SoulX-Podcast. The model supports cross-dialect prompting, where
      a Mandarin prompt can generate speech in target dialects with Dialect-Guided Prompting (DGP) method." style="width:60%; height:auto;">
    </div>

    <h2 id="pipeline" style="text-align: center;">SoulX-Data-Pipeline<a name="pipeline"></a></h2>
    <p style="text-align: justify;">In contrast to monologue speech, the processing of dialogue speech necessitates not only obtaining
      aligned transcripts but also distinguishing between speakers explicitly. As shown in Figure 2, the
      overall workflow comprises speech enhancement, audio segmentation and speaker diarization, text
      transcription, and quality filtering. Additionally, to facilitate paralinguistic and dialectal controllability,
      further information is extracted and annotated</p>

    <div style="text-align:center;">
      <img src="src/figs/soulx_datapipeline_v3.png" alt="Processing pipeline for in-the-wild dialogue speech data" style="width:60%; height:auto;">
    </div>

    <hr>
    <h2 id="podcast-demo" style="text-align: center;">Podcast Generation: Multi-Speaker Conversation<a name="podcast-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">
      Demonstrate the naturalness and coherence of our model in multi-turn, multi-speaker podcast dialogue generation.</p>

    <table class="demo-table">
      <thead>
        <tr>
          <th style="width: 50%;">Dialogue Script (Speaker Turns)</th>
          <th style="width: 25%;">Reference Podcast Audio</th>
          <th style="width: 25%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            [S1] 嗯嗯，我想要再 call back 一下，你之前刚刚讲的是，在这个临床上面其实并不能够让它提效。这个是基于 Research 呢？还是基于政策在这个 Policy 这个 level 方面呢，不能提效。我不知道这个能不能帮我们 break down 一下？嗯。
            <br>[S2] 就一方面的话，其实还是技术本身。当然这个次技术，它是一个我觉得是有史以来最伟大的人工智能，在生物学的一个，就是进展和发现和一个提升。但是它还是会出现错误，还是会出现原子重叠的现象。所以这些错误在 biology 这个领域或者药物研发的领域，它是不能容错的，这是一个问题。
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/zh_1_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/zh_1_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_zh1.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1] 对对对，物物源其实还是挺不错的。就比如说你早，你晚上去可能就没货了，但你早晨去一般都是有货的。像我今天早晨，嗯，他们一看了我就冲进去了。然后基本上平时想买买不到东西全部都有货。
            <br>[S2] 对，说到那个厕纸啊，你说就美国人为什么开始囤厕纸啊？我一开始以为这是谣言。然后呢，其实美国人一直没有反应，直到这上上周，就是呃那个股市熔断啊，然后再加上就是呃，就是宣布，就是各州紧急状况这样子发生。然后呢进超市要排队，结果呢我有，我在去超市的路上看到一对，就是中年夫妇吧，然后两个人两只手都捆满了厕纸。然后我才知道原来这件事情是真的。
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/zh_2_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/zh_2_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_zh2.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1] I'm sorry for snapping. That was very unprofessional of me. Let's move to the recap of the match.
            <br>[S2] Right it was it was kind of a great one though I mean you gotta admit Alice even though your surrogate did not claim the victory it was really a legendary match almost
            <br>[S1] It really was It was one for the books absolutely Survay and Cerceiv were supposed to meet uh in only four bouts, but there was a bit of a disturbance early on in the match. 
            <br>[S2] Yeah, somebody got onto the field. They were shouting something. I couldn't hear it, Alice. And honestly, I was just glad when the guards finally dragged them away. I just wanted to get back to the joust, but it did disturb the entire thing. And it riled the crowd up too, which was surprising. 
            <br>[S1] It's true, it later reports came out that the person who stormed the field to cause such a ruckus was a protester against Against your uncle, the emperor. 
            <br>[S2] Why would anybody want to protest against my uncle, the emperor? The single greatest living human person, maybe even greater than human person on the face of this planet or any other, you know. 
            <br>[S2] Of course, the emperor is benevolent and generous and A very very kind ruler.  
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/en_1_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/en_1_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_en1.wav" type="audio/wav">
            </audio>  
          </td>
        </tr>
        <tr>
          <td>
            [S1] OK, so the question I've been asking everybody to start with is how did you get into magic? 
            <br>[S2] So, this is phenomenal, actually. I have a fun little tidbit, just recently. Isn't a few days ago, I got a little pop up on my Facebook, um, in my Facebook memories, if that makes sense. Where it actually reminded me of the exact day, literally the exact day that I learned how to play Magic. And it was 9 years ago, and I learned how to play Magic. I'm from Southern California. I had just moved to San Diego, and I didn't know anyone. I knew like four people in the entire city. 
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/en_2_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/en_2_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_en2.wav" type="audio/wav">
            </audio>  
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="dialect-demo" style="text-align: center;">Dialectal Controls: Cross-Dialect Synthesis<a name="dialect-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">Demonstrate the model's ability to generate speech in different Chinese dialects (such as Cantonese, Sichuanese, and Henanese), including dialect switching and voice color preservation.</p>

    <table class="demo-table">
      <thead>
        <tr>
          <th style="width: 55%;">Dialogue Script</th>
          <th style="width: 10%;">Target Dialect</th>
          <th style="width: 17.5%;">Reference Audio (Source Speaker)</th>
          <th style="width: 17.5%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            [S1] 哈囉大家好啊，歡迎收聽我哋嘅節目。喂，我今日想問你樣嘢啊，你覺唔覺得，嗯，而家揸電動車，最煩，最煩嘅一樣嘢係咩啊？
            <br>[S2] 梗係充電啦。大佬啊，搵個位都已經好煩，搵到個位仲要喺度等，你話快極都要半個鐘一個鐘，真係，有時諗起都覺得好冇癮。
            <br>[S1] 係咪先。如果我而家同你講，充電可以快到同入油差唔多時間，你信唔信先？喂你平時喺油站入滿一缸油，要幾耐啊？五六分鐘？
            <br>[S2] 差唔多啦，七八分鐘，點都走得啦。電車喎，可以做到咁快？你咪玩啦。
          </td>
          <td>Cantonese (粤语)</td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_yue_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_yue_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_yue.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1]各位《巴适得板》的听众些，大家好噻！我是你们主持人晶晶。今儿天气硬是巴适，不晓得大家是在赶路嘛，还是茶都泡起咯，准备跟我们好生摆一哈龙门阵喃？
            <br>[S2]晶晶好哦，大家安逸噻！我是李老倌。你刚开口就川味十足，"摆龙门阵"几个字一甩出来，我鼻子头都闻到茶香跟火锅香咯！
            <br>[S1]就是得嘛！李老倌，我前些天带个外地朋友切人民公园鹤鸣茶社坐了一哈。他硬是搞不醒豁，为啥子我们一堆人围到杯茶就可以吹一下午壳子，从隔壁子王嬢嬢娃儿耍朋友，扯到美国大选，中间还掺几盘斗地主。他说我们四川人简直是把"摸鱼"刻进骨子里头咯！
            <br>[S2]哈哈，你那个朋友说得倒是有点儿趣，但他莫看到精髓噻。"摆龙门阵"哪是摸鱼嘛，这是我们川渝人特有的交际方式，更是一种活法。外省人天天说的"松弛感"，根根儿就在这龙门阵里头。今天我们就要好生摆一哈，为啥子四川人活得这么舒坦。就先从茶馆这个老窝子说起，看它咋个成了我们四川人的魂儿！
          </td>
          <td>Sichuanese (四川话)</td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_sichuan_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_sichuan_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_sichuan.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1]哎，大家好啊，欢迎收听咱这一期嘞《瞎聊呗，就这么说》，我是恁嘞老朋友，燕子。
            <br>[S2]大家好，我是老张。燕子啊，今儿瞅瞅你这个劲儿，咋着，是有啥可得劲嘞事儿想跟咱唠唠？
            <br>[S1]哎哟，老张，你咋恁懂我嘞！我跟你说啊，最近我刷手机，老是刷住些可逗嘞方言视频，特别是咱河南话，咦～我哩个乖乖，一听我都憋不住笑，咋说嘞，得劲儿哩很，跟回到家一样。
            <br>[SDeS2]哈哈哈哈，你这回可算说到根儿上了！河南话，咱往大处说说，中原官话，它真嘞是有一股劲儿搁里头。它可不光是说话，它脊梁骨后头藏嘞，是咱一整套、鲜鲜活活嘞过法儿，一种活人嘞道理。
            <fbr>[S1]活人嘞道理？哎，这你这一说，我嘞兴致“腾”一下就上来啦！觉住咱这嗑儿，一下儿从搞笑视频蹿到文化顶上了啊。那你赶紧给我白话白话，这里头到底有啥道道儿？我特别想知道——为啥一提起咱河南人，好些人脑子里“蹦”出来嘞头一个词儿，就是实在？这个实在，骨子里到底是啥嘞？ 
          </td>
          <td>Henanese (河南话)</td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_henan_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_henan_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_henan.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="paralinguistic-demo" style="text-align: center;">Paralinguistic Controls: Emotion & Style<a name="paralinguistic-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">Demonstrate the model's ability to control non-linguistic information (such as emotion, speech rate, and pauses) in speech.</p>

    <table class="demo-table">
      <thead>
        <tr>
          <th style="width: 55%;">Text Input (with Non-Verbal Tags)</th>
          <th style="width: 10%;">Target Style</th>
          <th style="width: 17.5%;">Reference Audio</th>
          <th style="width: 17.5%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            [S1]哈喽，AI时代的冲浪先锋们！欢迎收听《AI生活进行时》，啊，一个充满了未来感，然后，还有一点点，<b>&lt;|laughter|&gt;</b> ，神经质的播客节目，我是主持人小希。
            <br>[S2]<b>&lt;|throat_clearing|&gt;</b>，我是唠嗑。
            <br>[S1]最近活得特别赛博朋克哈！以前觉得AI是科幻片里的，<b>&lt;|sigh|&gt;</b> 现在，现在连我妈都用AI写广场舞文案了。
            <br>[S2]<b>&lt;|laughter|&gt;</b>这个例子特别生动。生成式AI已经从遥远概念变成日常工具，掀起了生产力变革。
            <br>[S1]对的。
            <br>[S2]所以今天咱们不聊"神经网络"这种头大的，嗯，就聊AI<b>&lt;|breathing|&gt;</b> 人工智能是怎么钻进普通人日常生活。
            <br>[S1]嗯嗯，没错。
            <br>[S2]<b>&lt;|coughing|&gt;</b>技术价值就是要体现在应用上！比如写作能力。我那个程序员朋友，用ChatGPT三分钟就能写出感情充沛的周报<b>&lt;|laughter|&gt;</b>把老板都看傻了。
          </td> 
          <td>
            <b>Non-Verbal Sounds</b><br>
            (Laughter, Sigh, Clearing Throat, etc.)
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_nonverbal_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_nonverbal_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_nonverbal.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="longform-demo" style="text-align: center;">Long-form Podcast: Coherence and Stability<a name="longform-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">Demonstrate the model's ability to generate long-form podcast conversations (over 60 minutes) with stable voice colors and coherent emotional continuity.</p>

    <div class="case" data-key="longform-scroll" data-json="raw/text/longform-scroll.json" 
         style="margin: 20px auto; width: 80%; max-width: 900px; text-align: left; padding: 20px; border: 1px solid #ddd; border-radius: 8px; background: #f9f9f9;">
      
      <h3 style="text-align: center; margin-top: 0;">Long-form Podcast Conversation (~60 Minutes)</h3>
      <p style="font-size: 14px; margin-bottom: 20px; color: #555; text-align: center;">
        <b>Topic:</b> Discussion of the 《Psychological Decoding》.
        </p>
      
      <div style="margin-bottom: 20px;">
        <p style="font-weight: bold; margin-bottom: 5px; color: #333;">Reference Audio:</p>
        <b>Speaker 1 Prompt:</b>
        <audio controls style="width: 100%; margin-top: 5px;">
          <source src="raw/prompt/podcast_long_prompt_spk1.wav" type="audio/wav">
        </audio>
        <br>
        <b>Speaker 2 Prompt:</b>
        <audio controls style="width: 100%; margin-top: 8px;">
          <source src="raw/prompt/podcast_long_prompt_spk2.wav" type="audio/wav">
        </audio>
      </div>
      
      <div>
        <p style="font-weight: bold; margin-bottom: 5px; color: #333;">SoulX-Podcast Generated Audio (Full):</p>
        <audio preload="metadata" controls style="width: 100%;">
          <source src="raw/samples/podcast_long_v3.mp3" type="audio/mp3">
        </audio>
        
        <div class="transcript" id="trans-longform-scroll">
          </div>
      </div>
      
      <!-- <p style="font-size: 12px; text-align: right; margin-top: 15px; color: #888;">
        *It is recommended to use headphones to evaluate the consistency of voice and the fluency of the conversation.* -->
      </p>
    </div>
    </section>
    
<script>
/* ---- 全局互斥播放：一个播放，其他暂停 ---- */
// 这个脚本会找到页面上所有的 <audio> 标签，确保一次只有一个在播放。
const allAudios = Array.from(document.querySelectorAll('audio'));
allAudios.forEach(p => p.addEventListener('play', () => {
  allAudios.forEach(o => { if (o !== p) o.pause(); });
}));

/* ---- 对齐播放器 ---- */
function mmssms(t){
  const m = Math.floor(t/60), s = Math.floor(t%60), ms = Math.floor((t-Math.floor(t))*1000);
  return `${String(m).padStart(2,'0')}:${String(s).padStart(2,'0')}.${String(ms).padStart(3,'0')}`;
}

class SyncPlayer{
  constructor(key, segs){
    this.audio     = document.getElementById(`audio-${key}`);
    this.transEl = document.getElementById(`trans-${key}`);
    this.idx = -1;
    this.segments = segs.slice().sort((a,b)=>a.start-b.start);
    for(let i=0;i<this.segments.length;i++){
      const cur=this.segments[i], nxt=this.segments[i+1];
      if (cur.end == null) cur.end = nxt ? nxt.start : Infinity;
    }
    this.shouldScroll = false; // 仅在用户主动跳转时滚动
    this.render(); this.bind();
  }
  esc(s){
    return String(s||'').replace(/[&<>"']/g, ch => (
      {'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[ch]
    ));
  }
  render(){
    this.transEl.innerHTML = '';
    this.segments.forEach((seg,i)=>{
      const d = document.createElement('div');
      d.className = 'line';
      d.dataset.idx = i;
      d.innerHTML = `
        <div class="ts">${mmssms(seg.start)}</div>
        <div class="spk">${this.esc(seg.speaker || '')}</div>
        <div class="txt">${this.esc(seg.text)}</div>
      `;
      d.onclick = () => this.seek(seg.start, true, true);
      this.transEl.appendChild(d);
    });
  }
  seek(t, autoplay=false, scroll=false){
    this.shouldScroll = !!scroll;
    this.audio.currentTime = Math.max(0, t);
    if (autoplay) this.audio.play().catch(()=>{});
  }
  findIdx(t){
    let lo=0, hi=this.segments.length-1, ans=-1;
    while (lo<=hi){
      const mid=(lo+hi)>>1, seg=this.segments[mid];
      if (t < seg.start) hi=mid-1;
      else if (t >= seg.end) lo=mid+1;
      else { ans=mid; break; }
    }
    // 如果没找到（例如在片段之间），尝试返回前一个
    if (ans === -1 && t > 0) {
        if (lo >= this.segments.length) return this.segments.length - 1;
        if (hi < 0) return -1; // 尚未开始
        return hi; // 返回前一个
    }
    return ans;
  }
  setActive(i, scroll=true){
    const prev = this.idx >= 0 ? this.transEl.querySelector(`.line[data-idx="${this.idx}"]`) : null;
    const next = i >= 0 ? this.transEl.querySelector(`.line[data-idx="${i}"]`) : null;

    if (i === this.idx){
      if (scroll && next && this.shouldScroll){ // 仅在 shouldScroll 为 true 时（用户点击或seek）才滚动
        const c=this.transEl;
        const targetTop = next.offsetTop - c.offsetTop;
        const maxTop = c.scrollHeight - c.clientHeight;
        c.scrollTo({ top: Math.max(0, Math.min(targetTop, maxTop)), behavior: 'smooth' });
        this.shouldScroll = false; // 重置滚动标志
      }
      return;
    }
    if (prev) prev.classList.remove('active');
    if (next){
      next.classList.add('active');
      if (scroll){ // 自动播放或用户点击时滚动
        const c=this.transEl;
        const targetTop = next.offsetTop - c.offsetTop - (c.clientHeight / 4); // 滚动到 1/4 处，而不是顶部
        const maxTop = c.scrollHeight - c.clientHeight;
        c.scrollTo({ top: Math.max(0, Math.min(targetTop, maxTop)), behavior: 'smooth' });
      }
    }
    this.idx = i;
  }
  onTime(){
    const i = this.findIdx(this.audio.currentTime);
    // 播放时始终启用滚动，除非音频已暂停
    const doScroll = !this.audio.paused || this.shouldScroll;
    this.setActive(i, doScroll);
    if(this.audio.paused) this.shouldScroll = false; // 暂停时重置
  }
  bind(){
    const t = () => this.onTime();
    this.audio.addEventListener('timeupdate', t);
    this.audio.addEventListener('seeked',  () => { this.shouldScroll = true; this.onTime(); });
    this.audio.addEventListener('seeking', () => { this.shouldScroll = true; });
    this.audio.addEventListener('play', t);
    this.audio.addEventListener('loadedmetadata', ()=>{
      const dur = isFinite(this.audio.duration) ? this.audio.duration : Infinity;
      for (let i=0;i<this.segments.length;i++){
        if (this.segments[i].end === Infinity) this.segments[i].end = dur;
      }
    });
  }
}

/* ---- 初始化所有 case ---- */
function initCases(){
  document.querySelectorAll('.case').forEach(section => {
    const key  = section.dataset.key;
    const json = section.dataset.json;
    if (!key || !json) return;
    // 让 audio 与 key 对应
    const audioEl = section.querySelector('audio[preload]'); // 查找带 preload 的音频
    const transEl = section.querySelector('.transcript');
    if (audioEl && transEl){
      audioEl.id  = `audio-${key}`;
      transEl.id  = `trans-${key}`;
    } else if (audioEl && !transEl) {
        // 容错：如果用户忘了加 trans-id
        const autoTransEl = document.getElementById(`trans-${key}`);
        if(autoTransEl) audioEl.id = `audio-${key}`;
    } else if (transEl && !audioEl) {
        // 容错：如果用户忘了加 audio-id
        const autoAudioEl = document.getElementById(`audio-${key}`);
        if(autoAudioEl) transEl.id = `trans-${key}`;
    }


    fetch(json)
      .then(r => r.json())
      .then(data => { new SyncPlayer(key, data); })
      .catch(err => console.error(`init ${key} failed:`, err));
  });
}
window.addEventListener('DOMContentLoaded', initCases);
</script>
</body>
</html>