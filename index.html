<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</title>
  <meta name="generator" content="Jekyll v3.9.0">
  <meta property="og:title" content="TODO: title">
  <meta property="og:locale" content="en_US">
  <meta name="twitter:card" content="summary">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="style.css">
</head>

<body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed="">
  <section class="page-header">
    </section>

  <section class="main-content">
    <h4 id="broadcast" style="margin: 1em 0; overflow: hidden; white-space: nowrap;">
      <div class="marquee-container">
        <div class="marquee-content">
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> SoulX-Podcast</a>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> SoulX-Podcast</a>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> SoulX-Podcast</a>
        </div>
      </div>
    </h4>
    
    <style>
    .marquee-container {
      display: flex;
      width: 100%;
      overflow: hidden;
    }
    .marquee-content {
      display: flex;
      animation: marquee 80s linear infinite;
      will-change: transform;
    }
    @keyframes marquee {
      0% { transform: translateX(100%); }
      100% { transform: translateX(-100%); }
    }
    .marquee-content a {
      color: #2563eb;
      text-decoration: underline;
      margin: 0 2px;
    }
    </style>
    
    <script>
    function stopMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'paused';
    }
    function startMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'running';
    }
    </script>
    
    <h1 id="">
      <center>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</center>
    </h1>
  
    <div style="text-align:center; line-height:1.6; font-family:Arial, sans-serif;">
      <p align="center">
        Hanke Xie<sup>1,2</sup><sup>,*</sup>, Haopeng Lin<sup>2</sup><sup>,*</sup>, Wenxiao Cao<sup>2</sup>, Dake Guo<sup>1</sup>, Wenjie Tian<sup>1</sup>, 
        Jun Wu<sup>2</sup>, Hanlin Wen<sup>2</sup>, Ruixuan Shang<sup>2</sup>, Hongmei Liu<sup>2</sup>, Zhiqi Jiang<sup>2</sup>, 
        Yuepeng Jiang<sup>1</sup>, Wenxi Chen<sup>2,3</sup>, Ruiqi Yan<sup>2,3</sup>, Jiale Qian<sup>2</sup>, Yichao Yan<sup>2</sup>, 
        Shunshun Yin<sup>2</sup>, Ming Tao<sup>2</sup>, Xie Chen<sup>3</sup>, Lei Xie<sup>1</sup><sup>,â€¡</sup>, Xinsheng Wang<sup>2</sup><sup>,â€¡</sup>
      </p>      
      <p align="center">
        <sup>1</sup> Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University, Xiâ€™an, China <br>
        <sup>2</sup> Soul AI Lab, China <br>
        <sup>3</sup> X-LANCE Lab, Shanghai Jiao Tong University, China <br>
      </p>
    </div>

    <p align="center">
    ğŸ“‘ <a href="https://arxiv.org/abs/2509.18004">Paper</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ™ <a href="https://github.com/Soul-AILab/SoulX-Podcast">GitHub</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ¤— <a href="https://huggingface.co/collections/Soul-AILab/soulx-podcast">HuggingFace</a>
    <br>
    ğŸ¤ <a href="https://github.com/Soul-AILab/SoulX-Podcast/blob/demopage/index.html">Demo Page</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ’¬ <a href="https://github.com/Soul-AILab/SoulX-Podcast?tab=readme-ov-file#contact">Contact Us</a>
    </p>

    <div style="text-align:center; margin-top:10px; position: sticky; top: 10px; z-index: 1000;">
      <nav style="
        background: rgba(0, 0, 0, 0.5);
        padding: 12px 24px;
        display: inline-block;
        border-radius: 10px;
        backdrop-filter: blur(6px);
      ">
        <a href="#abstract" class="nav-link">Abstract</a>
        <a href="#video" class="nav-link">Demo Video</a>
        <a href="#model" class="nav-link">Model Overview</a>
        <a href="#podcast-demo" class="nav-link">Podcast Generation</a> 
        <a href="#dialect-demo" class="nav-link">Dialectal Controls</a>
        <a href="#paralinguistic-demo" class="nav-link">Paralinguistic Controls</a>
        <a href="#longform-demo" class="nav-link">Long-form Podcast</a>
      </nav>
    </div>
    
    <style>
      .nav-link {
        color: white;
        margin: 0 15px;
        text-decoration: none;
        font-size: 16px;
        transition: color 0.2s, text-decoration 0.2s;
      }
      .nav-link:hover {
        color: #66ccff;
        text-decoration: underline;
      }
    </style>

    <style>
      /* è¡¨æ ¼é€šç”¨ç¾åŒ– */
      .demo-table {
        margin: 2em auto;
        width: 95%;
        border-collapse: collapse;
        text-align: center; /* é»˜è®¤æ°´å¹³å±…ä¸­ */
        font-size: 1em; 
      }
      .demo-table th, .demo-table td {
        border: 1px solid #ccc;
        padding: 12px 15px;
        vertical-align: middle; /* æ ¸å¿ƒä¿®æ”¹ï¼šé»˜è®¤æ‰€æœ‰å•å…ƒæ ¼å‚ç›´å±…ä¸­ */
      }
      /* è¡¨å¤´æ ·å¼ */
      .demo-table th {
        background-color: #f4f4f4;
        font-weight: 600;
      }
      
      /* è„šæœ¬åˆ—æ ·å¼ */
      .demo-table td:first-child {
        text-align: left;    /* è¦†ç›–æ°´å¹³å±…ä¸­ */
        font-size: 0.9em;    /* å‡å°å­—ä½“ */
        line-height: 1.5;    /* å‡å°è¡Œè· */
        vertical-align: top; /* æ ¸å¿ƒä¿®æ”¹ï¼šè¦†ç›–å‚ç›´å±…ä¸­ï¼Œä¿æŒé¡¶éƒ¨å¯¹é½ */
      }
      
      /* å‚è€ƒéŸ³é¢‘å®¹å™¨æ ·å¼ */
      .ref-audio-container {
        text-align: left; /* è¦†ç›–æ°´å¹³å±…ä¸­ */
        padding-left: 20px !important; 
      }
      .ref-audio-container b {
        font-size: 0.95em;
        color: #333;
      }
      .ref-audio-container audio {
        width: 100%; 
        max-width: 250px;
        margin-top: 4px;
        margin-bottom: 8px; 
      }
      
      /* ===== (æ–°) VibeVoice æ»šåŠ¨å­—å¹•æ ·å¼ ===== */
      .transcript {
        max-height: 30vh; /* è®¾å®šä¸€ä¸ªæœ€å¤§é«˜åº¦ */
        overflow-y: auto; /* å…è®¸å‚ç›´æ»šåŠ¨ */
        padding: 8px;
        border: 1px solid #ddd; /* ç»Ÿä¸€è¾¹æ¡† */
        border-radius: 8px; /* ç»Ÿä¸€åœ†è§’ */
        background: #fff;
        scroll-behavior: smooth;
        margin-top: 15px; /* ä¸ä¸Šæ–¹æ’­æ”¾å™¨ç•™å‡ºé—´è· */
      }
      .line {
        display: grid;
        grid-template-columns: 84px 75px 1fr; /* æ—¶é—´ | è¯´è¯äºº | æ–‡æœ¬ */
        gap: 10px;
        padding: 8px 10px;
        border-radius: 6px;
        border: 1px solid transparent;
        cursor: pointer;
        font-size: 0.9em;
        line-height: 1.5;
      }
      .line:hover {
        background: #f7f7f7;
      }
      .line.active {
        background: rgba(0, 102, 204, 0.08); /* é«˜äº®èƒŒæ™¯è‰² */
        border-color: #0066cc; /* é«˜äº®è¾¹æ¡†è‰² */
      }
      .ts, .spk {
        font-family: ui-monospace, Menlo, Consolas, monospace;
        color: #333;
        font-size: 14px;
        align-self: center; /* å‚ç›´å±…ä¸­ */
        opacity: .9;
        white-space: nowrap;
      }
      .ts { text-align: right; }
      .spk { text-align: left; font-weight: 600; }
      .txt {
        white-space: pre-wrap;
        word-break: break-word;
        overflow-wrap: anywhere;
        text-align: left; /* æ–‡æœ¬å·¦å¯¹é½ */
      }
      /* ================================== */
    </style>
    <h2 id="abstract" style="text-align: center;">Abstract<a name="abstract"></a></h2>
    <p style="text-align: justify;">Recent advances in text-to-speech (TTS) synthesis have significantly improved speech expressiveness and naturalness. However, most existing systems are tailored for single-speaker synthesis and fall short in generating coherent multi-speaker conversational speech. This technical report presents SoulX-Podcast, a system designed for podcast-style multi-turn, multi-speaker dialogic speech generation, while also achieving state-of-the-art performance in conventional text-to-speech (TTS) tasks.
      To meet the higher naturalness demands of multi-turn spoken dialogue, SoulX-Podcast integrates a range of paralinguistic controls and supports both Mandarin and English, as well as several Chinese dialects, including Sichuanese, Henanese, and Cantonese, enabling more personalized podcast-style speech generation. Experimental results demonstrate that SoulX-Podcast can continuously produce over 90 minutes of conversation with stable speaker timbre and smooth speaker transitions. Moreover, speakers exhibit contextually adaptive prosody, reflecting natural rhythm and intonation changes as dialogues progress. Across multiple evaluation metrics, SoulX-Podcast achieves state-of-the-art performance in both monologue TTS and multi-turn conversational speech synthesis.
    </p>


    <h2 id="video" style="text-align:center;">Demo Video</h2>
    
    <div style="display:flex; justify-content:center; gap:40px; margin-top:20px; flex-wrap:wrap;">
      <div style="text-align:center; max-width:900px; width:100%;">
        <div style="position:relative; width:100%; max-width:900px; aspect-ratio:16/9; background:#000;">
        <iframe 
          width="100%" 
          height="100%" 
          src="raw/video/demo_video.mp4" 
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
          allowfullscreen
          style="position:absolute; inset:0;"
        ></iframe>
        </div>
      </div>
    </div>

    <h2 id="model overview" style="text-align: center;">Model Overview<a name="model overview"></a></h2>
    <div style="text-align:center;">
      <img src="src/figs/soulxpodcast_v3.png" alt="Model overview of SoulX-Podcast. The model supports cross-dialect prompting, where
      a Mandarin prompt can generate speech in target dialects with Dialect-Guided Prompting (DGP) method." style="width:60%; height:auto;">
    </div>

    <h2 id="pipeline" style="text-align: center;">SoulX-Data-Pipeline<a name="pipeline"></a></h2>
    <p style="text-align: justify;">In contrast to monologue speech, the processing of dialogue speech necessitates not only obtaining
      aligned transcripts but also distinguishing between speakers explicitly. As shown in Figure 2, the
      overall workflow comprises speech enhancement, audio segmentation and speaker diarization, text
      transcription, and quality filtering. Additionally, to facilitate paralinguistic and dialectal controllability,
      further information is extracted and annotated</p>

    <div style="text-align:center;">
      <img src="src/figs/soulx_datapipeline_v3.png" alt="Processing pipeline for in-the-wild dialogue speech data" style="width:60%; height:auto;">
    </div>

    <hr>
    <h2 id="podcast-demo" style="text-align: center;">Podcast Generation: Multi-Speaker Conversation<a name="podcast-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">
      Demonstrate the naturalness and coherence of our model in multi-turn, multi-speaker podcast dialogue generation.</p>

    <table class="demo-table">
      <thead>
        <tr>
          <th style="width: 50%;">Dialogue Script (Speaker Turns)</th>
          <th style="width: 25%;">Reference Podcast Audio</th>
          <th style="width: 25%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            [S1] å—¯å—¯ï¼Œæˆ‘æƒ³è¦å† call back ä¸€ä¸‹ï¼Œä½ ä¹‹å‰åˆšåˆšè®²çš„æ˜¯ï¼Œåœ¨è¿™ä¸ªä¸´åºŠä¸Šé¢å…¶å®å¹¶ä¸èƒ½å¤Ÿè®©å®ƒææ•ˆã€‚è¿™ä¸ªæ˜¯åŸºäº Research å‘¢ï¼Ÿè¿˜æ˜¯åŸºäºæ”¿ç­–åœ¨è¿™ä¸ª Policy è¿™ä¸ª level æ–¹é¢å‘¢ï¼Œä¸èƒ½ææ•ˆã€‚æˆ‘ä¸çŸ¥é“è¿™ä¸ªèƒ½ä¸èƒ½å¸®æˆ‘ä»¬ break down ä¸€ä¸‹ï¼Ÿå—¯ã€‚
            <br>[S2] å°±ä¸€æ–¹é¢çš„è¯ï¼Œå…¶å®è¿˜æ˜¯æŠ€æœ¯æœ¬èº«ã€‚å½“ç„¶è¿™ä¸ªæ¬¡æŠ€æœ¯ï¼Œå®ƒæ˜¯ä¸€ä¸ªæˆ‘è§‰å¾—æ˜¯æœ‰å²ä»¥æ¥æœ€ä¼Ÿå¤§çš„äººå·¥æ™ºèƒ½ï¼Œåœ¨ç”Ÿç‰©å­¦çš„ä¸€ä¸ªï¼Œå°±æ˜¯è¿›å±•å’Œå‘ç°å’Œä¸€ä¸ªæå‡ã€‚ä½†æ˜¯å®ƒè¿˜æ˜¯ä¼šå‡ºç°é”™è¯¯ï¼Œè¿˜æ˜¯ä¼šå‡ºç°åŸå­é‡å çš„ç°è±¡ã€‚æ‰€ä»¥è¿™äº›é”™è¯¯åœ¨ biology è¿™ä¸ªé¢†åŸŸæˆ–è€…è¯ç‰©ç ”å‘çš„é¢†åŸŸï¼Œå®ƒæ˜¯ä¸èƒ½å®¹é”™çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/zh_1_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/zh_1_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_zh1.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1] å¯¹å¯¹å¯¹ï¼Œç‰©ç‰©æºå…¶å®è¿˜æ˜¯æŒºä¸é”™çš„ã€‚å°±æ¯”å¦‚è¯´ä½ æ—©ï¼Œä½ æ™šä¸Šå»å¯èƒ½å°±æ²¡è´§äº†ï¼Œä½†ä½ æ—©æ™¨å»ä¸€èˆ¬éƒ½æ˜¯æœ‰è´§çš„ã€‚åƒæˆ‘ä»Šå¤©æ—©æ™¨ï¼Œå—¯ï¼Œä»–ä»¬ä¸€çœ‹äº†æˆ‘å°±å†²è¿›å»äº†ã€‚ç„¶ååŸºæœ¬ä¸Šå¹³æ—¶æƒ³ä¹°ä¹°ä¸åˆ°ä¸œè¥¿å…¨éƒ¨éƒ½æœ‰è´§ã€‚
            <br>[S2] å¯¹ï¼Œè¯´åˆ°é‚£ä¸ªå•çº¸å•Šï¼Œä½ è¯´å°±ç¾å›½äººä¸ºä»€ä¹ˆå¼€å§‹å›¤å•çº¸å•Šï¼Ÿæˆ‘ä¸€å¼€å§‹ä»¥ä¸ºè¿™æ˜¯è°£è¨€ã€‚ç„¶åå‘¢ï¼Œå…¶å®ç¾å›½äººä¸€ç›´æ²¡æœ‰ååº”ï¼Œç›´åˆ°è¿™ä¸Šä¸Šå‘¨ï¼Œå°±æ˜¯å‘ƒé‚£ä¸ªè‚¡å¸‚ç†”æ–­å•Šï¼Œç„¶åå†åŠ ä¸Šå°±æ˜¯å‘ƒï¼Œå°±æ˜¯å®£å¸ƒï¼Œå°±æ˜¯å„å·ç´§æ€¥çŠ¶å†µè¿™æ ·å­å‘ç”Ÿã€‚ç„¶åå‘¢è¿›è¶…å¸‚è¦æ’é˜Ÿï¼Œç»“æœå‘¢æˆ‘æœ‰ï¼Œæˆ‘åœ¨å»è¶…å¸‚çš„è·¯ä¸Šçœ‹åˆ°ä¸€å¯¹ï¼Œå°±æ˜¯ä¸­å¹´å¤«å¦‡å§ï¼Œç„¶åä¸¤ä¸ªäººä¸¤åªæ‰‹éƒ½æ†æ»¡äº†å•çº¸ã€‚ç„¶åæˆ‘æ‰çŸ¥é“åŸæ¥è¿™ä»¶äº‹æƒ…æ˜¯çœŸçš„ã€‚
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/zh_2_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/zh_2_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_zh2.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1] I'm sorry for snapping. That was very unprofessional of me. Let's move to the recap of the match.
            <br>[S2] Right it was it was kind of a great one though I mean you gotta admit Alice even though your surrogate did not claim the victory it was really a legendary match almost
            <br>[S1] It really was It was one for the books absolutely Survay and Cerceiv were supposed to meet uh in only four bouts, but there was a bit of a disturbance early on in the match. 
            <br>[S2] Yeah, somebody got onto the field. They were shouting something. I couldn't hear it, Alice. And honestly, I was just glad when the guards finally dragged them away. I just wanted to get back to the joust, but it did disturb the entire thing. And it riled the crowd up too, which was surprising. 
            <br>[S1] It's true, it later reports came out that the person who stormed the field to cause such a ruckus was a protester against Against your uncle, the emperor. 
            <br>[S2] Why would anybody want to protest against my uncle, the emperor? The single greatest living human person, maybe even greater than human person on the face of this planet or any other, you know. 
            <br>[S2] Of course, the emperor is benevolent and generous and A very very kind ruler.  
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/en_1_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/en_1_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_en1.wav" type="audio/wav">
            </audio>  
          </td>
        </tr>
        <tr>
          <td>
            [S1] OK, so the question I've been asking everybody to start with is how did you get into magic? 
            <br>[S2] So, this is phenomenal, actually. I have a fun little tidbit, just recently. Isn't a few days ago, I got a little pop up on my Facebook, um, in my Facebook memories, if that makes sense. Where it actually reminded me of the exact day, literally the exact day that I learned how to play Magic. And it was 9 years ago, and I learned how to play Magic. I'm from Southern California. I had just moved to San Diego, and I didn't know anyone. I knew like four people in the entire city. 
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/en_2_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/en_2_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_en2.wav" type="audio/wav">
            </audio>  
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="dialect-demo" style="text-align: center;">Dialectal Controls: Cross-Dialect Synthesis<a name="dialect-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">Demonstrate the model's ability to generate speech in different Chinese dialects (such as Cantonese, Sichuanese, and Henanese), including dialect switching and voice color preservation.</p>

    <table class="demo-table">
      <thead>
        <tr>
          <th style="width: 55%;">Dialogue Script</th>
          <th style="width: 10%;">Target Dialect</th>
          <th style="width: 17.5%;">Reference Audio (Source Speaker)</th>
          <th style="width: 17.5%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            [S1] å“ˆå›‰å¤§å®¶å¥½å•Šï¼Œæ­¡è¿æ”¶è½æˆ‘å“‹å˜…ç¯€ç›®ã€‚å–‚ï¼Œæˆ‘ä»Šæ—¥æƒ³å•ä½ æ¨£å˜¢å•Šï¼Œä½ è¦ºå””è¦ºå¾—ï¼Œå—¯ï¼Œè€Œå®¶æ¸é›»å‹•è»Šï¼Œæœ€ç…©ï¼Œæœ€ç…©å˜…ä¸€æ¨£å˜¢ä¿‚å’©å•Šï¼Ÿ
            <br>[S2] æ¢—ä¿‚å……é›»å•¦ã€‚å¤§ä½¬å•Šï¼Œæµå€‹ä½éƒ½å·²ç¶“å¥½ç…©ï¼Œæµåˆ°å€‹ä½ä»²è¦å–ºåº¦ç­‰ï¼Œä½ è©±å¿«æ¥µéƒ½è¦åŠå€‹é˜ä¸€å€‹é˜ï¼ŒçœŸä¿‚ï¼Œæœ‰æ™‚è«—èµ·éƒ½è¦ºå¾—å¥½å†‡ç™®ã€‚
            <br>[S1] ä¿‚å’ªå…ˆã€‚å¦‚æœæˆ‘è€Œå®¶åŒä½ è¬›ï¼Œå……é›»å¯ä»¥å¿«åˆ°åŒå…¥æ²¹å·®å””å¤šæ™‚é–“ï¼Œä½ ä¿¡å””ä¿¡å…ˆï¼Ÿå–‚ä½ å¹³æ™‚å–ºæ²¹ç«™å…¥æ»¿ä¸€ç¼¸æ²¹ï¼Œè¦å¹¾è€å•Šï¼Ÿäº”å…­åˆ†é˜ï¼Ÿ
            <br>[S2] å·®å””å¤šå•¦ï¼Œä¸ƒå…«åˆ†é˜ï¼Œé»éƒ½èµ°å¾—å•¦ã€‚é›»è»Šå–ï¼Œå¯ä»¥åšåˆ°å’å¿«ï¼Ÿä½ å’ªç©å•¦ã€‚
          </td>
          <td>Cantonese (ç²¤è¯­)</td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_yue_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_yue_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_yue.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1]å„ä½ã€Šå·´é€‚å¾—æ¿ã€‹çš„å¬ä¼—äº›ï¼Œå¤§å®¶å¥½å™»ï¼æˆ‘æ˜¯ä½ ä»¬ä¸»æŒäººæ™¶æ™¶ã€‚ä»Šå„¿å¤©æ°”ç¡¬æ˜¯å·´é€‚ï¼Œä¸æ™“å¾—å¤§å®¶æ˜¯åœ¨èµ¶è·¯å˜›ï¼Œè¿˜æ˜¯èŒ¶éƒ½æ³¡èµ·å’¯ï¼Œå‡†å¤‡è·Ÿæˆ‘ä»¬å¥½ç”Ÿæ‘†ä¸€å“ˆé¾™é—¨é˜µå–ƒï¼Ÿ
            <br>[S2]æ™¶æ™¶å¥½å“¦ï¼Œå¤§å®¶å®‰é€¸å™»ï¼æˆ‘æ˜¯æè€å€Œã€‚ä½ åˆšå¼€å£å°±å·å‘³åè¶³ï¼Œ"æ‘†é¾™é—¨é˜µ"å‡ ä¸ªå­—ä¸€ç”©å‡ºæ¥ï¼Œæˆ‘é¼»å­å¤´éƒ½é—»åˆ°èŒ¶é¦™è·Ÿç«é”…é¦™å’¯ï¼
            <br>[S1]å°±æ˜¯å¾—å˜›ï¼æè€å€Œï¼Œæˆ‘å‰äº›å¤©å¸¦ä¸ªå¤–åœ°æœ‹å‹åˆ‡äººæ°‘å…¬å›­é¹¤é¸£èŒ¶ç¤¾åäº†ä¸€å“ˆã€‚ä»–ç¡¬æ˜¯æä¸é†’è±ï¼Œä¸ºå•¥å­æˆ‘ä»¬ä¸€å †äººå›´åˆ°æ¯èŒ¶å°±å¯ä»¥å¹ä¸€ä¸‹åˆå£³å­ï¼Œä»éš”å£å­ç‹å¬¢å¬¢å¨ƒå„¿è€æœ‹å‹ï¼Œæ‰¯åˆ°ç¾å›½å¤§é€‰ï¼Œä¸­é—´è¿˜æºå‡ ç›˜æ–—åœ°ä¸»ã€‚ä»–è¯´æˆ‘ä»¬å››å·äººç®€ç›´æ˜¯æŠŠ"æ‘¸é±¼"åˆ»è¿›éª¨å­é‡Œå¤´å’¯ï¼
            <br>[S2]å“ˆå“ˆï¼Œä½ é‚£ä¸ªæœ‹å‹è¯´å¾—å€’æ˜¯æœ‰ç‚¹å„¿è¶£ï¼Œä½†ä»–è«çœ‹åˆ°ç²¾é«“å™»ã€‚"æ‘†é¾™é—¨é˜µ"å“ªæ˜¯æ‘¸é±¼å˜›ï¼Œè¿™æ˜¯æˆ‘ä»¬å·æ¸äººç‰¹æœ‰çš„äº¤é™…æ–¹å¼ï¼Œæ›´æ˜¯ä¸€ç§æ´»æ³•ã€‚å¤–çœäººå¤©å¤©è¯´çš„"æ¾å¼›æ„Ÿ"ï¼Œæ ¹æ ¹å„¿å°±åœ¨è¿™é¾™é—¨é˜µé‡Œå¤´ã€‚ä»Šå¤©æˆ‘ä»¬å°±è¦å¥½ç”Ÿæ‘†ä¸€å“ˆï¼Œä¸ºå•¥å­å››å·äººæ´»å¾—è¿™ä¹ˆèˆ’å¦ã€‚å°±å…ˆä»èŒ¶é¦†è¿™ä¸ªè€çªå­è¯´èµ·ï¼Œçœ‹å®ƒå’‹ä¸ªæˆäº†æˆ‘ä»¬å››å·äººçš„é­‚å„¿ï¼
          </td>
          <td>Sichuanese (å››å·è¯)</td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_sichuan_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_sichuan_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_sichuan.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
        <tr>
          <td>
            [S1]å“ï¼Œå¤§å®¶å¥½å•Šï¼Œæ¬¢è¿æ”¶å¬å’±è¿™ä¸€æœŸå˜ã€ŠçèŠå‘—ï¼Œå°±è¿™ä¹ˆè¯´ã€‹ï¼Œæˆ‘æ˜¯æå˜è€æœ‹å‹ï¼Œç‡•å­ã€‚
            <br>[S2]å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯è€å¼ ã€‚ç‡•å­å•Šï¼Œä»Šå„¿ç…ç…ä½ è¿™ä¸ªåŠ²å„¿ï¼Œå’‹ç€ï¼Œæ˜¯æœ‰å•¥å¯å¾—åŠ²å˜äº‹å„¿æƒ³è·Ÿå’±å” å” ï¼Ÿ
            <br>[S1]å“å“Ÿï¼Œè€å¼ ï¼Œä½ å’‹ææ‡‚æˆ‘å˜ï¼æˆ‘è·Ÿä½ è¯´å•Šï¼Œæœ€è¿‘æˆ‘åˆ·æ‰‹æœºï¼Œè€æ˜¯åˆ·ä½äº›å¯é€—å˜æ–¹è¨€è§†é¢‘ï¼Œç‰¹åˆ«æ˜¯å’±æ²³å—è¯ï¼Œå’¦ï½æˆ‘å“©ä¸ªä¹–ä¹–ï¼Œä¸€å¬æˆ‘éƒ½æ†‹ä¸ä½ç¬‘ï¼Œå’‹è¯´å˜ï¼Œå¾—åŠ²å„¿å“©å¾ˆï¼Œè·Ÿå›åˆ°å®¶ä¸€æ ·ã€‚
            <br>[SDeS2]å“ˆå“ˆå“ˆå“ˆï¼Œä½ è¿™å›å¯ç®—è¯´åˆ°æ ¹å„¿ä¸Šäº†ï¼æ²³å—è¯ï¼Œå’±å¾€å¤§å¤„è¯´è¯´ï¼Œä¸­åŸå®˜è¯ï¼Œå®ƒçœŸå˜æ˜¯æœ‰ä¸€è‚¡åŠ²å„¿æé‡Œå¤´ã€‚å®ƒå¯ä¸å…‰æ˜¯è¯´è¯ï¼Œå®ƒè„Šæ¢éª¨åå¤´è—å˜ï¼Œæ˜¯å’±ä¸€æ•´å¥—ã€é²œé²œæ´»æ´»å˜è¿‡æ³•å„¿ï¼Œä¸€ç§æ´»äººå˜é“ç†ã€‚
            <fbr>[S1]æ´»äººå˜é“ç†ï¼Ÿå“ï¼Œè¿™ä½ è¿™ä¸€è¯´ï¼Œæˆ‘å˜å…´è‡´â€œè…¾â€ä¸€ä¸‹å°±ä¸Šæ¥å•¦ï¼è§‰ä½å’±è¿™å—‘å„¿ï¼Œä¸€ä¸‹å„¿ä»æç¬‘è§†é¢‘è¹¿åˆ°æ–‡åŒ–é¡¶ä¸Šäº†å•Šã€‚é‚£ä½ èµ¶ç´§ç»™æˆ‘ç™½è¯ç™½è¯ï¼Œè¿™é‡Œå¤´åˆ°åº•æœ‰å•¥é“é“å„¿ï¼Ÿæˆ‘ç‰¹åˆ«æƒ³çŸ¥é“â€”â€”ä¸ºå•¥ä¸€æèµ·å’±æ²³å—äººï¼Œå¥½äº›äººè„‘å­é‡Œâ€œè¹¦â€å‡ºæ¥å˜å¤´ä¸€ä¸ªè¯å„¿ï¼Œå°±æ˜¯å®åœ¨ï¼Ÿè¿™ä¸ªå®åœ¨ï¼Œéª¨å­é‡Œåˆ°åº•æ˜¯å•¥å˜ï¼Ÿ 
          </td>
          <td>Henanese (æ²³å—è¯)</td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_henan_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_henan_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_henan.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="paralinguistic-demo" style="text-align: center;">Paralinguistic Controls: Emotion & Style<a name="paralinguistic-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">Demonstrate the model's ability to control non-linguistic information (such as emotion, speech rate, and pauses) in speech.</p>

    <table class="demo-table">
      <thead>
        <tr>
          <th style="width: 55%;">Text Input (with Non-Verbal Tags)</th>
          <th style="width: 10%;">Target Style</th>
          <th style="width: 17.5%;">Reference Audio</th>
          <th style="width: 17.5%;">SoulX-Podcast Generated Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>
            [S1]å“ˆå–½ï¼ŒAIæ—¶ä»£çš„å†²æµªå…ˆé”‹ä»¬ï¼æ¬¢è¿æ”¶å¬ã€ŠAIç”Ÿæ´»è¿›è¡Œæ—¶ã€‹ï¼Œå•Šï¼Œä¸€ä¸ªå……æ»¡äº†æœªæ¥æ„Ÿï¼Œç„¶åï¼Œè¿˜æœ‰ä¸€ç‚¹ç‚¹ï¼Œ<b>&lt;|laughter|&gt;</b> ï¼Œç¥ç»è´¨çš„æ’­å®¢èŠ‚ç›®ï¼Œæˆ‘æ˜¯ä¸»æŒäººå°å¸Œã€‚
            <br>[S2]<b>&lt;|throat_clearing|&gt;</b>ï¼Œæˆ‘æ˜¯å” å—‘ã€‚
            <br>[S1]æœ€è¿‘æ´»å¾—ç‰¹åˆ«èµ›åšæœ‹å…‹å“ˆï¼ä»¥å‰è§‰å¾—AIæ˜¯ç§‘å¹»ç‰‡é‡Œçš„ï¼Œ<b>&lt;|sigh|&gt;</b> ç°åœ¨ï¼Œç°åœ¨è¿æˆ‘å¦ˆéƒ½ç”¨AIå†™å¹¿åœºèˆæ–‡æ¡ˆäº†ã€‚
            <br>[S2]<b>&lt;|laughter|&gt;</b>è¿™ä¸ªä¾‹å­ç‰¹åˆ«ç”ŸåŠ¨ã€‚ç”Ÿæˆå¼AIå·²ç»ä»é¥è¿œæ¦‚å¿µå˜æˆæ—¥å¸¸å·¥å…·ï¼Œæ€èµ·äº†ç”Ÿäº§åŠ›å˜é©ã€‚
            <br>[S1]å¯¹çš„ã€‚
            <br>[S2]æ‰€ä»¥ä»Šå¤©å’±ä»¬ä¸èŠ"ç¥ç»ç½‘ç»œ"è¿™ç§å¤´å¤§çš„ï¼Œå—¯ï¼Œå°±èŠAI<b>&lt;|breathing|&gt;</b> äººå·¥æ™ºèƒ½æ˜¯æ€ä¹ˆé’»è¿›æ™®é€šäººæ—¥å¸¸ç”Ÿæ´»ã€‚
            <br>[S1]å—¯å—¯ï¼Œæ²¡é”™ã€‚
            <br>[S2]<b>&lt;|coughing|&gt;</b>æŠ€æœ¯ä»·å€¼å°±æ˜¯è¦ä½“ç°åœ¨åº”ç”¨ä¸Šï¼æ¯”å¦‚å†™ä½œèƒ½åŠ›ã€‚æˆ‘é‚£ä¸ªç¨‹åºå‘˜æœ‹å‹ï¼Œç”¨ChatGPTä¸‰åˆ†é’Ÿå°±èƒ½å†™å‡ºæ„Ÿæƒ…å……æ²›çš„å‘¨æŠ¥<b>&lt;|laughter|&gt;</b>æŠŠè€æ¿éƒ½çœ‹å‚»äº†ã€‚
          </td> 
          <td>
            <b>Non-Verbal Sounds</b><br>
            (Laughter, Sigh, Clearing Throat, etc.)
          </td>
          <td class="ref-audio-container">
            <b>Speaker 1:</b>
            <audio controls><source src="raw/prompt/podcast_nonverbal_prompt_spk1.wav" type="audio/wav"></audio>
            <b>Speaker 2:</b>
            <audio controls><source src="raw/prompt/podcast_nonverbal_prompt_spk2.wav" type="audio/wav"></audio>
          </td>
          <td>
            <audio controls style="width: 90%; max-width: 250px;">
              <source src="raw/samples/podcast_nonverbal.wav" type="audio/wav">
            </audio>
          </td>
        </tr>
      </tbody>
    </table>

    <hr>
    <h2 id="longform-demo" style="text-align: center;">Long-form Podcast: Coherence and Stability<a name="longform-demo"></a></h2>
    <p style="text-align: center; color: #555; margin-top: 10px;">Demonstrate the model's ability to generate long-form podcast conversations (over 60 minutes) with stable voice colors and coherent emotional continuity.</p>

    <div class="case" data-key="longform-scroll" data-json="raw/text/longform-scroll.json" 
         style="margin: 20px auto; width: 80%; max-width: 900px; text-align: left; padding: 20px; border: 1px solid #ddd; border-radius: 8px; background: #f9f9f9;">
      
      <h3 style="text-align: center; margin-top: 0;">Long-form Podcast Conversation (~60 Minutes)</h3>
      <p style="font-size: 14px; margin-bottom: 20px; color: #555; text-align: center;">
        <b>Topic:</b> Discussion of the ã€ŠPsychological Decodingã€‹.
        </p>
      
      <div style="margin-bottom: 20px;">
        <p style="font-weight: bold; margin-bottom: 5px; color: #333;">Reference Audio:</p>
        <b>Speaker 1 Prompt:</b>
        <audio controls style="width: 100%; margin-top: 5px;">
          <source src="raw/prompt/podcast_long_prompt_spk1.wav" type="audio/wav">
        </audio>
        <br>
        <b>Speaker 2 Prompt:</b>
        <audio controls style="width: 100%; margin-top: 8px;">
          <source src="raw/prompt/podcast_long_prompt_spk2.wav" type="audio/wav">
        </audio>
      </div>
      
      <div>
        <p style="font-weight: bold; margin-bottom: 5px; color: #333;">SoulX-Podcast Generated Audio (Full):</p>
        <audio preload="metadata" controls style="width: 100%;">
          <source src="raw/samples/podcast_long_v3.mp3" type="audio/mp3">
        </audio>
        
        <div class="transcript" id="trans-longform-scroll">
          </div>
      </div>
      
      <!-- <p style="font-size: 12px; text-align: right; margin-top: 15px; color: #888;">
        *It is recommended to use headphones to evaluate the consistency of voice and the fluency of the conversation.* -->
      </p>
    </div>
    </section>
    
<script>
/* ---- å…¨å±€äº’æ–¥æ’­æ”¾ï¼šä¸€ä¸ªæ’­æ”¾ï¼Œå…¶ä»–æš‚åœ ---- */
// è¿™ä¸ªè„šæœ¬ä¼šæ‰¾åˆ°é¡µé¢ä¸Šæ‰€æœ‰çš„ <audio> æ ‡ç­¾ï¼Œç¡®ä¿ä¸€æ¬¡åªæœ‰ä¸€ä¸ªåœ¨æ’­æ”¾ã€‚
const allAudios = Array.from(document.querySelectorAll('audio'));
allAudios.forEach(p => p.addEventListener('play', () => {
  allAudios.forEach(o => { if (o !== p) o.pause(); });
}));

/* ---- å¯¹é½æ’­æ”¾å™¨ ---- */
function mmssms(t){
  const m = Math.floor(t/60), s = Math.floor(t%60), ms = Math.floor((t-Math.floor(t))*1000);
  return `${String(m).padStart(2,'0')}:${String(s).padStart(2,'0')}.${String(ms).padStart(3,'0')}`;
}

class SyncPlayer{
  constructor(key, segs){
    this.audio     = document.getElementById(`audio-${key}`);
    this.transEl = document.getElementById(`trans-${key}`);
    this.idx = -1;
    this.segments = segs.slice().sort((a,b)=>a.start-b.start);
    for(let i=0;i<this.segments.length;i++){
      const cur=this.segments[i], nxt=this.segments[i+1];
      if (cur.end == null) cur.end = nxt ? nxt.start : Infinity;
    }
    this.shouldScroll = false; // ä»…åœ¨ç”¨æˆ·ä¸»åŠ¨è·³è½¬æ—¶æ»šåŠ¨
    this.render(); this.bind();
  }
  esc(s){
    return String(s||'').replace(/[&<>"']/g, ch => (
      {'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[ch]
    ));
  }
  render(){
    this.transEl.innerHTML = '';
    this.segments.forEach((seg,i)=>{
      const d = document.createElement('div');
      d.className = 'line';
      d.dataset.idx = i;
      d.innerHTML = `
        <div class="ts">${mmssms(seg.start)}</div>
        <div class="spk">${this.esc(seg.speaker || '')}</div>
        <div class="txt">${this.esc(seg.text)}</div>
      `;
      d.onclick = () => this.seek(seg.start, true, true);
      this.transEl.appendChild(d);
    });
  }
  seek(t, autoplay=false, scroll=false){
    this.shouldScroll = !!scroll;
    this.audio.currentTime = Math.max(0, t);
    if (autoplay) this.audio.play().catch(()=>{});
  }
  findIdx(t){
    let lo=0, hi=this.segments.length-1, ans=-1;
    while (lo<=hi){
      const mid=(lo+hi)>>1, seg=this.segments[mid];
      if (t < seg.start) hi=mid-1;
      else if (t >= seg.end) lo=mid+1;
      else { ans=mid; break; }
    }
    // å¦‚æœæ²¡æ‰¾åˆ°ï¼ˆä¾‹å¦‚åœ¨ç‰‡æ®µä¹‹é—´ï¼‰ï¼Œå°è¯•è¿”å›å‰ä¸€ä¸ª
    if (ans === -1 && t > 0) {
        if (lo >= this.segments.length) return this.segments.length - 1;
        if (hi < 0) return -1; // å°šæœªå¼€å§‹
        return hi; // è¿”å›å‰ä¸€ä¸ª
    }
    return ans;
  }
  setActive(i, scroll=true){
    const prev = this.idx >= 0 ? this.transEl.querySelector(`.line[data-idx="${this.idx}"]`) : null;
    const next = i >= 0 ? this.transEl.querySelector(`.line[data-idx="${i}"]`) : null;

    if (i === this.idx){
      if (scroll && next && this.shouldScroll){ // ä»…åœ¨ shouldScroll ä¸º true æ—¶ï¼ˆç”¨æˆ·ç‚¹å‡»æˆ–seekï¼‰æ‰æ»šåŠ¨
        const c=this.transEl;
        const targetTop = next.offsetTop - c.offsetTop;
        const maxTop = c.scrollHeight - c.clientHeight;
        c.scrollTo({ top: Math.max(0, Math.min(targetTop, maxTop)), behavior: 'smooth' });
        this.shouldScroll = false; // é‡ç½®æ»šåŠ¨æ ‡å¿—
      }
      return;
    }
    if (prev) prev.classList.remove('active');
    if (next){
      next.classList.add('active');
      if (scroll){ // è‡ªåŠ¨æ’­æ”¾æˆ–ç”¨æˆ·ç‚¹å‡»æ—¶æ»šåŠ¨
        const c=this.transEl;
        const targetTop = next.offsetTop - c.offsetTop - (c.clientHeight / 4); // æ»šåŠ¨åˆ° 1/4 å¤„ï¼Œè€Œä¸æ˜¯é¡¶éƒ¨
        const maxTop = c.scrollHeight - c.clientHeight;
        c.scrollTo({ top: Math.max(0, Math.min(targetTop, maxTop)), behavior: 'smooth' });
      }
    }
    this.idx = i;
  }
  onTime(){
    const i = this.findIdx(this.audio.currentTime);
    // æ’­æ”¾æ—¶å§‹ç»ˆå¯ç”¨æ»šåŠ¨ï¼Œé™¤ééŸ³é¢‘å·²æš‚åœ
    const doScroll = !this.audio.paused || this.shouldScroll;
    this.setActive(i, doScroll);
    if(this.audio.paused) this.shouldScroll = false; // æš‚åœæ—¶é‡ç½®
  }
  bind(){
    const t = () => this.onTime();
    this.audio.addEventListener('timeupdate', t);
    this.audio.addEventListener('seeked',  () => { this.shouldScroll = true; this.onTime(); });
    this.audio.addEventListener('seeking', () => { this.shouldScroll = true; });
    this.audio.addEventListener('play', t);
    this.audio.addEventListener('loadedmetadata', ()=>{
      const dur = isFinite(this.audio.duration) ? this.audio.duration : Infinity;
      for (let i=0;i<this.segments.length;i++){
        if (this.segments[i].end === Infinity) this.segments[i].end = dur;
      }
    });
  }
}

/* ---- åˆå§‹åŒ–æ‰€æœ‰ case ---- */
function initCases(){
  document.querySelectorAll('.case').forEach(section => {
    const key  = section.dataset.key;
    const json = section.dataset.json;
    if (!key || !json) return;
    // è®© audio ä¸ key å¯¹åº”
    const audioEl = section.querySelector('audio[preload]'); // æŸ¥æ‰¾å¸¦ preload çš„éŸ³é¢‘
    const transEl = section.querySelector('.transcript');
    if (audioEl && transEl){
      audioEl.id  = `audio-${key}`;
      transEl.id  = `trans-${key}`;
    } else if (audioEl && !transEl) {
        // å®¹é”™ï¼šå¦‚æœç”¨æˆ·å¿˜äº†åŠ  trans-id
        const autoTransEl = document.getElementById(`trans-${key}`);
        if(autoTransEl) audioEl.id = `audio-${key}`;
    } else if (transEl && !audioEl) {
        // å®¹é”™ï¼šå¦‚æœç”¨æˆ·å¿˜äº†åŠ  audio-id
        const autoAudioEl = document.getElementById(`audio-${key}`);
        if(autoAudioEl) transEl.id = `trans-${key}`;
    }


    fetch(json)
      .then(r => r.json())
      .then(data => { new SyncPlayer(key, data); })
      .catch(err => console.error(`init ${key} failed:`, err));
  });
}
window.addEventListener('DOMContentLoaded', initCases);
</script>
</body>
</html>