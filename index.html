<!DOCTYPE html>
<!-- saved from url=(0033)https://QicongXie.github.io/end2endvc/ -->
<html lang="en-US">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
  <title>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</title>
  <meta name="generator" content="Jekyll v3.9.0">
  <meta property="og:title" content="TODO: title">
  <meta property="og:locale" content="en_US">
  <meta name="twitter:card" content="summary">
  <!-- End Jekyll SEO tag -->

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="style.css">
</head>

<body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed="">
  <section class="page-header">
    <!-- <h1 class="project-name">Demo PAGE</h1> -->
    <!-- <h2 class="project-tagline"></h2> -->
  </section>

  <section class="main-content">
    <!-- <h3 id="">
      <center>ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast. <a href="https://github.com/Soul-AILab/SoulX-Podcast">WenetSpeech-Yue</a></center>
    </h3> -->
    
    <h4 id="broadcast" style="margin: 1em 0; overflow: hidden; white-space: nowrap;">
      <div class="marquee-container">
        <!-- æ ¸å¿ƒä¿®å¤ï¼šåœ¨ "at" åæ·»åŠ ç©ºæ ¼ï¼Œå†è¡”æ¥è¶…é“¾æ¥ -->
        <div class="marquee-content">
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> WenetSpeech-Yue</a>
          <!-- ç”¨è¶³å¤Ÿç©ºæ ¼åˆ†éš”é‡å¤å†…å®¹ï¼Œç¡®ä¿æ— ç¼è¡”æ¥ä¸æ‹¥æŒ¤ -->
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> WenetSpeech-Yue</a>
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          ğŸ“¢: The latest AI podcast model is here! Soul AI Lab open-sources the SOTA Text To Speech model SoulX-Podcast.&nbsp;
          <a href="https://github.com/Soul-AILab/SoulX-Podcast" target="_blank" onmouseover="stopMarquee()" onmouseout="startMarquee()"> WenetSpeech-Yue</a>
        </div>
      </div>
    </h4>
    
    <style>
    .marquee-container {
      display: flex;
      width: 100%;
      overflow: hidden;
    }
    /* æ»šåŠ¨é€Ÿåº¦è°ƒæ…¢ï¼ˆ80ç§’/è½®ï¼Œæ•°å€¼è¶Šå¤§è¶Šæ…¢ï¼‰ï¼Œä¿ç•™æ— é™å¾ªç¯ */
    .marquee-content {
      display: flex;
      animation: marquee 80s linear infinite;
      will-change: transform; /* æå‡åŠ¨ç”»æµç•…åº¦ */
    }
    @keyframes marquee {
      0% { transform: translateX(100%); } /* ä»å³ä¾§å®Œå…¨è¿›å…¥ */
      100% { transform: translateX(-100%); } /* ä»å·¦ä¾§å®Œå…¨é€€å‡ºï¼Œæ— ç¼è¡”æ¥ */
    }
    /* å¯é€‰ï¼šç»™é“¾æ¥åŠ  hover æ ·å¼ï¼Œæç¤ºå¯äº¤äº’ */
    .marquee-content a {
      color: #2563eb; /* é“¾æ¥è“è‰²ï¼Œé€‚é…å¤šæ•°é¡µé¢é£æ ¼ */
      text-decoration: underline;
      margin: 0 2px; /* é¿å…é“¾æ¥ä¸å‰åæ–‡æœ¬è´´å¤ªè¿‘ */
    }
    </style>
    
    <script>
    // ç²¾å‡†æ§åˆ¶åŠ¨ç”»æš‚åœ/æ’­æ”¾ï¼ˆåªé’ˆå¯¹æ»šåŠ¨å†…å®¹ï¼Œä¸å½±å“å…¶ä»–å…ƒç´ ï¼‰
    function stopMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'paused';
    }
    function startMarquee() {
      document.querySelector('.marquee-content').style.animationPlayState = 'running';
    }
    </script>
    
    <h1 id="">
      <center>SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity</center>
    </h1>
  
    <div style="text-align:center; line-height:1.6; font-family:Arial, sans-serif;">
      <p align="center">
        Hanke Xie<sup>1,2</sup><sup>,*</sup>, Haopeng Lin<sup>2</sup><sup>,*</sup>, Wenxiao Cao<sup>2</sup>, Dake Guo<sup>1</sup>, Wenjie Tian<sup>1</sup>, 
        Jun Wu<sup>2</sup>, Hanlin Wen<sup>2</sup>, Ruixuan Shang<sup>2</sup>, Hongmei Liu<sup>2</sup>, Zhiqi Jiang<sup>2</sup>, 
        Yuepeng Jiang<sup>1</sup>, Wenxi Chen<sup>2</sup>, Ruiqi Yan<sup>2</sup>, Jiale Qian<sup>2</sup>, Yichao Yan<sup>2</sup>, 
        Shunshun Yin<sup>2</sup>, Ming Tao<sup>2</sup>, Lei Xie<sup>1</sup><sup>,â•€</sup>, Xinsheng Wang<sup>2</sup><sup>,â€ </sup>
      </p>      
    <p align="center">
      <sup>1</sup> Audio, Speech and Language Processing Group (ASLP@NPU), Northwestern Polytechnical University, Xiâ€™an, China <br>
      <sup>2</sup> Soul AI Lab, China <br>
    </p>
      
  </div>


    <p align="center">
    ğŸ“‘ <a href="https://arxiv.org/abs/2509.18004">Paper</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ™ <a href="https://github.com/Soul-AILab/SoulX-Podcast">GitHub</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ¤— <a href="https://huggingface.co/collections/Soul-AILab/soulx-podcast">HuggingFace</a>
    <br>
    <!-- ğŸ–¥ï¸ <a href="https://huggingface.co/spaces/ASLP-lab/WenetSpeech-Yue">HuggingFace Space</a> &nbsp&nbsp | &nbsp&nbsp  -->
    ğŸ¤ <a href="https://github.com/Soul-AILab/SoulX-Podcast/blob/demopage/index.html">Demo Page</a> &nbsp&nbsp | &nbsp&nbsp 
    ğŸ’¬ <a href="https://github.com/Soul-AILab/SoulX-Podcast?tab=readme-ov-file#contact">Contact Us</a>
    </p>

    <!-- å¯¼èˆªæ ï¼šå±…ä¸­ã€è‡ªé€‚åº”å®½åº¦ã€åŠé€æ˜ + è·Ÿéšé¡µé¢ç§»åŠ¨ -->
    <div style="text-align:center; margin-top:10px; position: sticky; top: 10px; z-index: 1000;">
      <nav style="
        background: rgba(0, 0, 0, 0.5);
        padding: 12px 24px;
        display: inline-block;      /* å®½åº¦éšå†…å®¹ */
        border-radius: 10px;
        backdrop-filter: blur(6px); /* æ¯›ç»ç’ƒï¼Œæ”¯æŒçš„æµè§ˆå™¨ä¼šæ›´å¥½çœ‹ */
      ">
        <a href="#abstract" class="nav-link">Abstract</a>
        <a href="#video" class="nav-link">Demo Video</a>
        <a href="#model" class="nav-link">Model Overview</a>
        <a href="#dataset" class="nav-link">WenetSpeech-Chuan</a>
        <a href="#podcast" class="nav-link">Podcast Generation</a>
        <a href="#dialect" class="nav-link">Dialectal Controls</a>
        <a href="#paralinguistic" class="nav-link">Paralinguistic Controls</a>
        <a href="#longform-podcast" class="nav-link">Long-form Podcast</a>
      </nav>
    </div>
    
    <style>
      /* é“¾æ¥æ ·å¼ï¼šä¿æŒåŸå­—å·ï¼Œhover å˜è“+ä¸‹åˆ’çº¿ */
      .nav-link {
        color: white;
        margin: 0 15px;
        text-decoration: none;
        font-size: 16px;             /* ä½ åŸæ¥çš„å¤§å° */
        transition: color 0.2s, text-decoration 0.2s;
      }
      .nav-link:hover {
        color: #66ccff;              /* æµ…è“è‰² hover */
        text-decoration: underline;
      }
    </style>


    <h2 id="abstract" style="text-align: center;">Abstract<a name="abstract"></a></h2>
    <p style="text-align: justify;">Recent advances in text-to-speech (TTS) synthesis have significantly improved
      speech expressiveness and naturalness. However, most existing systems are tailored
      for single-speaker synthesis and fall short in generating coherent multi-speaker
      conversational speech. This technical report presents SoulX-Podcast, a system
      designed for multi-turn, multi-speaker conversational speech generation while si-
      multaneously achieving state-of-the-art performance in conventional TTS tasks. To
      meet the higher naturalness demands of multi-turn spoken dialogue, SoulX-Podcast
      integrates a range of paralinguistic controls and supports both Mandarin and En-
      glish, as well as several Chinese dialects, including Sichuanese, Henanese, and
      Cantonese, enabling more personalized podcast-style speech generation. Experi-
      mental results demonstrate that SoulX-Podcast can continuously produce over 90
      minutes of conversation with stable speaker timbre and smooth speaker transitions.
      Moreover, speakers exhibit contextually adaptive prosody, reflecting natural rhythm
      and intonation changes as dialogues progress. Across multiple evaluation metrics,
      SoulX-Podcast achieves state-of-the-art performance in both single-speaker TTS
      and multi-turn conversational speech synthesis.</p>


    <h2 id="video" style="text-align:center;">Demo Video</h2>
    
    <div style="display:flex; justify-content:center; gap:40px; margin-top:20px; flex-wrap:wrap;">
      <div style="text-align:center; max-width:900px; width:100%;">
        <!-- <h3>Sichuanese</h3> -->
        <div style="position:relative; width:100%; max-width:900px; aspect-ratio:16/9; background:#000;">
        <iframe 
          width="100%" 
          height="100%" 
          src="raw/video/demo_video.mp4" 
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
          allowfullscreen
          style="position:absolute; inset:0;"
        ></iframe>
        </div>
      </div>
    </div>

    <h2 id="model overview" style="text-align: center;">Model Overview<a name="model overview"></a></h2>
    <div style="text-align:center;">
      <img src="src/figs/soulxpodcast_infer.pdf" alt="Model overviewof SoulX-Podcast. The model supports cross-dialect prompting, where
      a Mandarin prompt can generate speech in target dialects with Dialect-Guided Prompting (DGP) method." style="width:80%; height:auto;">
    </div>

    <h2 id="pipeline" style="text-align: center;">SoulX-Data-Pipeline<a name="pipeline"></a></h2>
    <p style="text-align: justify;">In contrast to monologue speech, the processing of dialogue speech necessitates not only obtaining
      aligned transcripts but also distinguishing between speakers explicitly. As shown in Figure 2, the
      overall workflow comprises speech enhancement, audio segmentation and speaker diarization, text
      transcription, and quality filtering. Additionally, to facilitate paralinguistic and dialectal controllability,
      further information is extracted and annotated</p>

    <div style="text-align:center;">
      <img src="src/figs/soulx_datapipeline_v3.png" alt="Processing pipeline for in-the-wild dialogue speech data" style="width:80%; height:auto;">
    </div>

    <h2 id="asr" style="text-align: center;">ASR Leaderboard<a name="Comparison"></a></h2>
    <h4>Leaderboard shows ASR Results (CER%â†“) on Sichuanese Datasets.</h4>
    <p><em>Note: <strong>Bold</strong> indicates best performance, <u>underlined</u> indicates second-best performance, and <span style="background-color: #d4edda; padding: 0 2px;">light green background</span> indicates models finetuned on a high-quality internal corpus (to show the system's potential as a foundation model).</em></p>
    
      <table style="margin:0 auto; border-collapse: collapse; text-align:center;">
        <tr>
          <th align="left" rowspan="2">Model</th>
          <th align="center" rowspan="2">Model Size</th>
          <th align="center" colspan="3">WSC-Eval-ASR</th>
          <th align="center" colspan="2">Magicdata</th>
          <th align="center" rowspan="2">Avg.</th>
        </tr>
        <tr>
          <th align="center">Easy</th>
          <th align="center">Hard</th>
          <th align="center">Total</th>
          <th align="center">Conversation</th>
          <th align="center">Daily-Use</th>
        </tr>
      
        <tr><td align="left" colspan="8"><b>with LLM</b></td></tr>
        <tr>
          <td align="left">Kimi-Audio<sup></sup></td><td>7B</td><td>16.65</td><td>28.66</td><td>17.66</td><td>24.67</td><td><b>5.77</b></td><td>18.68</td>
        </tr>
        <tr>
          <td align="left">FireRedASR-LLM<sup></sup></td><td>8.3B</td><td>12.80</td><td>25.27</td><td>14.40</td><td>17.68</td><td>6.69</td><td>15.37</td>
        </tr>
        <tr>
          <td align="left">Qwen2.5-omni<sup></sup></td><td>3B</td><td>16.94</td><td>26.01</td><td>18.20</td><td>20.40</td><td>6.32</td><td>17.69</td>
        </tr>
        <tr>
          <td align="left">Qwen2.5-omni-WSC-Finetuneâ­</td><td>3B</td><td>14.36</td><td>24.14</td><td>15.61</td><td>18.45</td><td>6.15</td><td>15.74</td>
        </tr>
        <tr>
          <td align="left"><span style="background-color: #d4edda;">Qwen2.5-omni+internal dataâ­</span></td><td>3B</td><td>13.17</td><td>23.36</td><td>14.81</td><td>18.50</td><td>5.88</td><td>15.14</td>
        </tr>
        <tr>
          <td align="left"><span style="background-color: #d4edda;">Qwen2.5-omni-WSC-Finetune + internal dataâ­</span></td><td>3B</td><td>12.93</td><td>23.19</td><td>14.25</td><td>17.95</td><td><u>5.89</u></td><td>14.84</td>
        </tr>
      
        <tr><td align="left" colspan="8"><b>without LLM</b></td></tr>
        <tr>
          <td align="left">SenseVoice-small<sup></sup></td><td>234M</td><td>17.43</td><td>28.38</td><td>18.39</td><td>23.50</td><td>8.77</td><td>19.29</td>
        </tr>
        <tr>
          <td align="left">Whisper<sup></sup></td><td>244M</td><td>52.06</td><td>63.99</td><td>53.59</td><td>55.88</td><td>52.03</td><td>55.51</td>
        </tr>
        <tr>
          <td align="left">FireRedASR-AED<sup></sup></td><td>1.1B</td><td>13.29</td><td>23.64</td><td>14.62</td><td>17.84</td><td>6.69</td><td>15.14</td>
        </tr>
        <tr>
          <td align="left">Paraformer<sup></sup></td><td>220M</td><td>14.34</td><td>24.61</td><td>15.66</td><td>19.81</td><td>8.16</td><td>16.52</td>
        </tr>
        <tr>
          <td align="left">Paraformer-WSC-Finetuneâ­</td><td>220M</td><td>12.15</td><td>22.60</td><td>13.51</td><td>16.60</td><td>8.02</td><td>14.58</td>
        </tr>
        <tr>
          <td align="left"><span style="background-color: #d4edda;">Paraformer + internal dataâ­</span></td><td>220M</td><td><u>11.93</u></td><td><u>21.82</u></td><td><u>13.14</u></td><td><u>15.61</u></td><td>6.77</td><td><u>13.85</u></td>
        </tr>
        <tr>
          <td align="left"><span style="background-color: #d4edda;">Paraformer-WSC-Finetune + internal dataâ­</span></td><td>220M</td><td><b>11.59</b></td><td><b>21.59</b></td><td><b>12.87</b></td><td><b>14.59</b></td><td>6.28</td><td><b>13.38</b></td>
        </tr>
      </table>



<h2 id="tts" style="text-align: center; margin-top: 40px;">TTS Evaluation</h2>

<table style="margin: 0 auto; border-collapse: collapse; text-align: center;">
  <tr>
    <th rowspan="2" align="left">Model</th>
    <th colspan="5">WSC-Eval-TTS-easy</th>
    <th colspan="5">WSC-Eval-TTS-hard</th>
  </tr>
  <tr>
    <th>CER(%)â†“</th>
    <th>SIM(%)â†‘</th>
    <th>IMOSâ†‘</th>
    <th>SMOSâ†‘</th>
    <th>AMOSâ†‘</th>
    <th>CER(%)â†“</th>
    <th>SIM(%)â†‘</th>
    <th>IMOSâ†‘</th>
    <th>SMOSâ†‘</th>
    <th>AMOSâ†‘</th>
  </tr>

  <tr>
    <td align="left">Step-Audio-TTS<sup>[21]</sup></td>
    <td>10.83</td><td>67.66</td><td>3.81</td><td>2.86</td><td>3.15</td>
    <td>12.52</td><td>54.52</td><td>3.75</td><td>2.77</td><td>3.06</td>
  </tr>
  <tr>
    <td align="left">CosyVoice 2.0<sup>[22]</sup></td>
    <td>7.14</td><td>70.27</td><td>3.88</td><td>3.10</td><td>3.69</td>
    <td>9.06</td><td>60.10</td><td>3.96</td><td>2.73</td><td>3.81</td>
  </tr>
  <tr>
    <td align="left">Qwen-TTS<sup>â€ </sup></td>
    <td><u>4.13</u></td><td>-</td><td>3.95</td><td>-</td><td>3.90</td>
    <td><u>7.35</u></td><td>-</td><td><b>4.02</b></td><td>-</td><td>3.88</td>
  </tr>
  <!-- <tr style="background-color: #d4edda;"> -->
    <td align="left"><span style="background-color: #d4edda;">CosyVoice2-WSCâ­</span></td>
    <td>4.28</td><td><u>72.78</u></td><td><b>4.13</b></td><td><u>3.94</u></td><td><u>4.05</u></td>
    <td>8.78</td><td><u>62.59</u></td><td>3.85</td><td><u>2.78</u></td><td><u>3.92</u></td>
  </tr>
  <!-- <tr style="background-color: #d4edda;"> -->
    <td align="left"><span style="background-color: #d4edda;">CosyVoice2-WSC-SFTâ­</span></td>
    <td><b>4.08</b></td><td><b>78.84</b></td><td><u>4.10</u></td><td><b>4.16</b></td><td><b>4.20</b></td>
    <td><b>7.22</b></td><td><b>67.96</b></td><td><u>4.01</u></td><td><b>3.03</b></td><td><b>3.98</b></td>
  </tr>
</table>



<!-- <div style="max-width: 900px; margin: 0 auto; font-size: 0.95em; color: #555; text-align: left;">
  <sup>&dagger;</sup> Commercial system with a single fixed speaker; speaker similarity is not evaluated.
</div> -->
<div style="font-size: 0.90em; color: #888; text-align: left; margin-top: 8px; margin-left: 2.5%; font-style: italic; max-width: 95%;">
  <sup>&dagger;</sup> Commercial system with a single fixed speaker; speaker similarity is not evaluated.
</div>


<h2 id="tts_demo" style="text-align: center;">TTS Demo<a name="Comparison"></a></h2>
<h3 id="tts_demo" style="text-align: center;">Model Comparison<a name="Comparison"></a></h3>

<p style="font-size: 14px; margin-top: 10px; color: #555;">
  CosyVoice2-WSC is a finetuned CosyVoice2 model using WenetSpeech-Chuan.
</p>
<p style="font-size: 14px; margin-top: 10px; color: #555;">
  Llasa-1B-WSC is a finetuned Llasa-1B model using WenetSpeech-Chuan.
</p>

  <table style="margin: 0 auto; width: 95%; border-collapse: collapse;">
    <thead>
      <tr id="header-row">
        <th>Text</th>
        <!-- JSä¼šæ’å…¥ç³»ç»Ÿå -->
      </tr>
    </thead>
    <tbody id="tbody">
      <tr><td colspan="8">Loading...</td></tr>
    </tbody>
  </table>


<br>
<h3 id="tts_demo" style="text-align: center;">CosyVoice2-WSC-SFT<a name="Comparison"></a></h3>
<p style="font-size: 14px; margin-top: 10px; color: #555;">
Further supervised fine-tune CosyVoice2-WSC with 100 hours of internal high-quality data from two fixed speakers.
</p>

<table style="margin: 0 auto; width: 95%; border-collapse: collapse; text-align: center; font-size: 1em;">
  <thead>
    <tr>
      <th style="border: 1px solid #ccc; padding: 12px; width: 20%;">Text</th>
      <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">Reference Audio</th>
      <th style="border: 1px solid #ccc; padding: 12px; width: 25%;">Synthetic Audio</th>
    </tr>
  </thead>
  <tbody>
    <!-- æ¨¡å‹1è¡Œ -->
    <tr>
      <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">æˆ‘è·Ÿä½ è¯´å“¦ï¼Œè¿™å‡ å¤©é‡åº†çš„å¤©æ°”çœŸçš„æ˜¯åˆçƒ­åˆæ¹¿ï¼Œç®€ç›´æ²¡æ³•å¿å—ï¼Œå‡ºé—¨èµ°å‡ æ­¥å°±å…¨èº«æ¹¿é€äº†ã€‚</td>
      <!-- ReferenceéŸ³é¢‘ï¼šå¼•ç”¨F01_ä¸­ç«‹_20054.wav -->
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/ref/F22_æ„¤æ€’_20012.wav" type="audio/wav">
        </audio>
      </td>
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/sys/5.wav" type="audio/wav">
          Your browser does not support the audio element.
      </td>
    </tr>
    <!-- æ¨¡å‹2è¡Œ -->
     <tr>
      <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">æˆ‘ä»¬å°±å½“åšå¥½äº‹ä¸€æ ·ï¼Œç»å¯¹ä¸è¦è®©è¿™æ ·å­çš„äº‹æƒ…å‘ç”Ÿã€‚é¢†å¯¼ç­”åº”ä¹‹åå“ˆï¼Œæˆ‘å°±è”ç³»äº†ä»–çš„å¦ˆè€æ±‰å„¿ï¼ŒæŠŠäº‹æƒ…éƒ½è·Ÿä»–ä»¬çš„è®²æ¸…æ¥šäº†ï¼Œç„¶åæŠŠé“¶è¡Œå¡å·æ‹¿åˆ°ä¹‹åï¼ŒæŒ‰æµç¨‹åŠç†äº†é€€æ¬¾ã€‚</td>
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/ref/F22_å¼€å¿ƒ_20007.wav" type="audio/wav">
        </audio>
      </td>
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/sys/10.wav" type="audio/wav">
          Your browser does not support the audio element.
      </td>
    </tr>
    <!-- æ¨¡å‹3è¡Œ -->
     <tr>
      <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">æ™šä¸Šå»åƒçƒ§çƒ¤ï¼Œæœ‹å‹éè¦ç‚¹ä¸ªå˜æ€è¾£çš„é¸¡ç¿…ï¼Œè¯´æ˜¯è¿‡ç˜¾ï¼Œç»“æœåƒäº†ä¸€å£çœ¼æ³ªéƒ½å‡ºæ¥äº†ï¼Œå˜´å·´åƒè¢«ç«çƒ§ä¸€æ ·ï¼ŒæœåŠ¡å‘˜éƒ½å“å¾—ç»™æˆ‘ä»¬é€ç‰›å¥¶æ¥ã€‚</td>
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/ref/sichuan_man_20211012398.wav" type="audio/wav">
        </audio>
      </td>
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/sys/3.wav" type="audio/wav">
          Your browser does not support the audio element.
      </td>
    </tr>
    <!-- æ¨¡å‹4è¡Œ -->
     <tr>
      <td style="border: 1px solid #ccc; padding: 12px; text-align: left;">ä½ è¯´è¯èƒ½ä¸èƒ½ä¸è¦é‚£ä¹ˆå†²ï¼Œæˆ‘è·Ÿä½ è®²ä¸æ˜¯æ¯ä¸ªäººéƒ½æƒ¯ç€ä½ è€æ€§å­çš„ï¼Œæˆ‘è„¾æ°”ä¹Ÿæœ‰ç‚¹å„¿çˆ†ï¼</td>
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/ref/sichuan_man_20211012399.wav" type="audio/wav">
        </audio>
      </td>
      <td style="border: 1px solid #ccc; padding: 12px;">
        <audio controls style="width: 90%; max-width: 250px;">
          <source src="raw/TTS_samples_1/sys/8.wav" type="audio/wav">
          Your browser does not support the audio element.
      </td>
    </tr>
    




  </tbody>
</table>




    
</section>
</body>

<script>
  // é…ç½®
  const systems = ["ref", "Cosyvoice2", "CosyVoice2-Chuan", "StepAudio", "Llasa-1B-Chuan"];
  const systemDisplayNames = {
    "ref": "Reference",
    "Llasa-1B-Chuan": "Llasa-1B-WSC",
    "Cosyvoice2": "Cosyvoice2",
    "StepAudio": "Step-Audio-TTS-3B",
    "CosyVoice2-Chuan": "CosyVoice2-WSC",
  };

  // åŠ¨æ€ç”Ÿæˆè¡¨å¤´
  const headerRow = document.getElementById('header-row');
  systems.forEach(sys => {
    const th = document.createElement('th');
    th.textContent = systemDisplayNames[sys] || sys;
    if (sys === "Llasa-1B-Chuan" || sys === "CosyVoice2-Chuan") {
      th.style.backgroundColor = "#ffe0b2"; // é«˜äº®é¢œè‰²
      th.style.fontWeight = "bold";
    }
    headerRow.appendChild(th);
  });

  // è¯»å–å¹¶è§£ætext.txt
  fetch('raw/TTS_samples/text.txt')
    .then(response => response.text())
    .then(text => {
      const lines = text.trim().split('\n');
      const data = lines.map(line => {
        const [filename, content] = line.split('|');
        return { filename: filename.trim(), text: content.trim() };
      });

      // ç”Ÿæˆè¡¨æ ¼å†…å®¹
      const tbody = document.getElementById('tbody');
      tbody.innerHTML = ""; // æ¸…ç©ºLoading
      data.forEach(item => {
        const tr = document.createElement('tr');
        // æ–‡æœ¬åˆ—
        const tdText = document.createElement('td');
        tdText.className = "text-cell";
        tdText.textContent = item.text;
        tr.appendChild(tdText);

        // å„ç³»ç»ŸéŸ³é¢‘
        systems.forEach(sys => {
          const td = document.createElement('td');
          if (sys === "Llasa-1B-Chuan" || sys === "CosyVoice2-Chuan") {
            td.style.backgroundColor = "#fff3e0"; // é«˜äº®é¢œè‰²
          }
          const audio = document.createElement('audio');
          audio.controls = true;
          audio.style.width = "180px";
          audio.src = `raw/TTS_samples/${sys}/${item.filename}.wav`;
          td.appendChild(audio);
          tr.appendChild(td);
        });
        tbody.appendChild(tr);
      });
    })
    .catch(err => {
      document.getElementById('tbody').innerHTML = `<tr><td colspan="${systems.length+1}">Failed to load text.txt: ${err}</td></tr>`;
    });
</script>


